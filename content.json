{"meta":{"title":"熟悉路线站点","subtitle":"本人是个小小程序员，之前一直是看大神博客学习，博客一是为了激励自己学习，二是记录自己的学习历程，以方便及时回顾相关知识。主要技术点包括Java后端，Spring框架，数据库，计算机基础知识，以及技术分享。","description":"","author":"duanjiaojiao","url":"https://duanjiaojiao316.github.io","root":"/"},"pages":[{"title":"你好","date":"2021-04-20T07:44:33.826Z","updated":"2021-04-20T07:44:33.826Z","comments":true,"path":"hello-world.html","permalink":"https://duanjiaojiao316.github.io/hello-world.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment"},{"title":"404 Not Found：该页无法显示","date":"2021-04-20T07:44:33.810Z","updated":"2021-04-20T07:44:33.810Z","comments":false,"path":"/404.html","permalink":"https://duanjiaojiao316.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2021-04-20T07:44:33.825Z","updated":"2021-04-20T07:44:33.825Z","comments":false,"path":"about/index.html","permalink":"https://duanjiaojiao316.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2021-04-20T07:44:33.825Z","updated":"2021-04-20T07:44:33.825Z","comments":false,"path":"books/index.html","permalink":"https://duanjiaojiao316.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2020-01-19T12:02:16.000Z","updated":"2021-04-20T07:44:33.825Z","comments":true,"path":"categories/index.html","permalink":"https://duanjiaojiao316.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-04-20T07:44:33.826Z","updated":"2021-04-20T07:44:33.826Z","comments":true,"path":"links/index.html","permalink":"https://duanjiaojiao316.github.io/links/index.html","excerpt":"","text":""},{"title":"项目","date":"2021-04-20T07:44:33.826Z","updated":"2021-04-20T07:44:33.826Z","comments":false,"path":"repository/index.html","permalink":"https://duanjiaojiao316.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-01-19T11:56:49.000Z","updated":"2021-04-20T07:44:33.826Z","comments":true,"path":"tags/index.html","permalink":"https://duanjiaojiao316.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"redis分布式锁","slug":"redis分布式锁","date":"2021-04-26T13:10:30.000Z","updated":"2021-05-11T07:46:58.353Z","comments":true,"path":"2021/04/26/redis分布式锁/","link":"","permalink":"https://duanjiaojiao316.github.io/2021/04/26/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"分布式锁，就是在分布式项目中使用的锁，控制分布式系统同步访问共享资源。 分布式锁需要满足的特性：1、互斥性。任何时刻，对于一条数据，保证只有一台应用可以获取分布式锁。 2、高可用性。分布式场景下小部分的服务器宕机不会影响正常运行。（提供分布式锁的服务以集群方式部署） 3、防止锁超时。客户端没有主动释放锁，服务器会在一段时间后自动释放，防止客户端宕机或者网络不可达等因素产生死锁。 4、独占性。加锁解锁必须是同一台服务器进行。（锁的持有者才能释放锁） 怎么获取锁？1231、SETNX，用法SETNX key value#SETNX是『 SET if Not eXists』(如果不存在，则 SET)的简写，设置成功就返回1，否则返回0。 可以看出，当把key为lock的值设置为”Java”后，再设置成别的值就会失败，看上去很简单，也好像独占了锁，但有个致命的问题，就是key没有过期时间，这样一来，除非手动删除key或者获取锁后设置过期时间，不然其他线程永远拿不到锁。 12SETNX Key 1EXPIRE Key Seconds 但是这个方案把获取锁和设置过期时间分成两步，没有原子性。（有可能获取锁成功，但是设置过期时间失败） 12342、SETEX，用法SETEX key seconds value#值 value 关联到 key ，并将 key 的生存时间设为 seconds (以秒为单位)。如果 key 已经存在，SETEX 命令将覆写旧值。 12343、PSETEX，用法PSETEX key milliseconds value#这个命令和SETEX命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像SETEX命令那样，以秒为单位。 不过，从Redis 2.6.12 版本开始，SET命令可以通过参数来实现和SETNX、SETEX、PSETEX 三个命令相同的效果。 1SET key value NX EX seconds 怎么释放锁？释放锁的命令就简单了，直接删除key就行，但我们前面说了，因为分布式锁必须由锁的持有者自己释放，所以我们必须先确保当前释放锁的线程是持有者，没问题了再删除，这样一来，就变成两个步骤了，似乎又违背了原子性了，怎么办呢？ 使用lua脚本把两步操作拼装。 123456if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1]then return redis.call(&quot;del&quot;,KEYS[1])else return 0end KEYS[1]是当前key的名称，ARGV[1]可以是当前线程的ID(或者其他不固定的值，能识别所属线程即可)，这样就可以防止持有过期锁的线程，或者其他线程误删现有锁的情况出现。 实现一个分布式锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.params.SetParams;import java.util.Collections;public class RedisDistributedLock &#123; /** * 获取响应锁的数据key */ private String LOCK_KEY = &quot;redis_lock&quot;; /** * 分布式锁自动过期时间5ms */ private long expireTime = 5; /** * 获取锁的最大连接时长1s */ private long timeOut = 1000; /** * redis命令参数，相当于nx和px的命令合集 */ private SetParams params = SetParams.setParams().nx().px(expireTime); /** * redis连接池 */ JedisPool jedisPool = new JedisPool(&quot;127.0.0.1&quot;,6379); /** * 获取锁 * @param id 线程的id，或者其他可识别当前线程且不重复的字段 * @return 是否获取到锁 */ public boolean lock(String id) &#123; Long start = System.currentTimeMillis(); Jedis jedis = jedisPool.getResource(); try &#123; for(;;)&#123; // lock 为设置key的结果 String lock = jedis.set(LOCK_KEY, id,params); if(&quot;OK&quot;.equals(lock)) &#123; return true; &#125; // 目前距离获取锁开始的时间间隔 long interval = System.currentTimeMillis() - start; if(interval &gt; timeOut) &#123; return false; &#125; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; finally &#123; jedis.close(); &#125; &#125; /** * 释放锁 * @param id 线程的id，或者其他可识别当前线程且不重复的字段 * @return */ public boolean unlock(String id) &#123; Jedis jedis = jedisPool.getResource(); // lua脚本字符串 String script = &quot;if redis.call(&#x27;get&#x27;,KEYS[1]) == ARGV[1] &quot; + &quot;then &quot; + &quot;return redis.call(&#x27;del&#x27;,KEYS[1]) &quot; + &quot;else &quot; + &quot;return 0 &quot; + &quot;end&quot;; try &#123; String result = jedis.eval(script, Collections.singletonList(LOCK_KEY), Collections.singletonList(id)).toString(); return &quot;1&quot;.equals(result); &#125; finally &#123; jedis.close(); &#125; &#125;&#125; 测试类 123456789101112131415161718192021222324import redisDemo.RedisDistributedLock;public class RedisDistributedLockTest &#123; private static RedisDistributedLock demo = new RedisDistributedLock(); private static Integer NUM = 101; public static void main(String[] args) &#123; for (int i = 0; i &lt; 100; i++) &#123; new Thread(() -&gt; &#123; String id = String.valueOf(Thread.currentThread().getId()); boolean isLock = demo.lock(id); try &#123; if (isLock) &#123; NUM--; System.out.println(NUM); &#125; &#125; finally &#123; demo.unlock(id); &#125; &#125;).start(); &#125; &#125;&#125; 分布式锁的缺陷一、客户端长时间阻塞导致锁失效问题 客户端1得到了锁，因为网络问题或者GC等原因导致长时间阻塞，然后业务程序还没执行完锁就过期了，这时候客户端2也能正常拿到锁，可能会导致线程安全的问题。 客户端长时间阻塞 二、redis服务器时钟漂移问题 如果redis服务器的机器时钟发生了向前跳跃，就会导致这个key过早超时失效，比如说客户端1拿到锁后，key的过期时间是12:02分，但redis服务器本身的时钟比客户端快了2分钟，导致key在12:00的时候就失效了，这时候，如果客户端1还没有释放锁的话，就可能导致多个客户端同时持有同一把锁的问题。 三、单点实例安全问题 如果redis是单master模式的，当这台机宕机的时候，那么所有的客户端都获取不到锁了，为了提高可用性，可能就会给这个master加一个slave，但是因为redis的主从同步是异步进行的，可能会出现客户端1设置完锁后，master挂掉，slave提升为master，因为异步复制的特性，客户端1设置的锁丢失了，这时候客户端2设置锁也能够成功，导致客户端1和客户端2同时拥有锁。 为了解决Redis单点问题，redis的作者提出了RedLock算法。 RedLock算法该算法的实现前提在于Redis必须是多节点部署的，可以有效防止单点故障，具体的实现思路是这样的： 1、获取当前时间戳（ms）； 2、先设定key的有效时长（TTL），超出这个时间就会自动释放，然后client（客户端）尝试使用相同的key和value对所有redis实例进行设置，每次链接redis实例时设置一个比TTL短很多的超时时间，这是为了不要过长时间等待已经关闭的redis服务。并且试着获取下一个redis实例。 比如：TTL（也就是过期时间）为5s，那获取锁的超时时间就可以设置成50ms，所以如果50ms内无法获取锁，就放弃获取这个锁，从而尝试获取下个锁； 3、client通过获取所有能获取的锁后的当前时间减去申请锁进行第一步的时间，还有redis服务器的时钟漂移误差，然后这个时间差要小于TTL时间并且成功设置锁的实例数&gt;= N/2 + 1（N为Redis实例的数量），也就是获取超过半数以上的redis实例的锁，那么加锁成功 比如TTL是5s，连接redis获取所有锁用了2s，然后再减去时钟漂移（假设误差是1s左右），那么锁的真正有效时长就只有2s了； 4、如果客户端由于某些原因获取锁失败，便会开始解锁所有redis实例。 RedLock算法的隐患好了，算法也介绍完了，从设计上看，毫无疑问，RedLock算法的思想主要是为了有效防止Redis单点故障的问题，而且在设计TTL的时候也考虑到了服务器时钟漂移的误差，让分布式锁的安全性提高了不少。 但事实真的是这样吗？反正我个人的话感觉效果一般般， 首先第一点，我们可以看到，在RedLock算法中，锁的有效时间会减去连接Redis实例的时长，如果这个过程因为网络问题导致耗时太长的话，那么最终留给锁的有效时长就会大大减少，客户端访问共享资源的时间很短，很可能程序处理的过程中锁就到期了。而且，锁的有效时间还需要减去服务器的时钟漂移，但是应该减多少合适呢，要是这个值设置不好，很容易出现问题。 然后第二点，这样的算法虽然考虑到用多节点来防止Redis单点故障的问题，但但如果有节点发生崩溃重启的话，还是有可能出现多个客户端同时获取锁的情况。 假设一共有5个Redis节点：A、B、C、D、E，客户端1和2分别加锁 客户端1成功锁住了A，B，C，获取锁成功（但D和E没有锁住）。 节点C的master挂了，然后锁还没同步到slave，slave升级为master后丢失了客户端1加的锁。 客户端2这个时候获取锁，锁住了C，D，E，获取锁成功。 这样，客户端1和客户端2就同时拿到了锁，程序安全的隐患依然存在。除此之外，如果这些节点里面某个节点发生了时间漂移的话，也有可能导致锁的安全问题。","categories":[],"tags":[]},{"title":"Redis主从架构数据同步原理","slug":"Redis主从架构数据同步原理","date":"2021-04-25T15:11:33.000Z","updated":"2021-05-11T07:46:58.341Z","comments":true,"path":"2021/04/25/Redis主从架构数据同步原理/","link":"","permalink":"https://duanjiaojiao316.github.io/2021/04/25/Redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86/","excerpt":"","text":"Redis主从架构数据同步原理主从架构如何保证数据一致性？读写分离。写操作只在主库，读执行操作主库和从库都可以执行。如果写操作可以在主库和从库进行，为了保持数据一致性就需要在Redis进行加锁，这样会减慢Redis的速度 如何搭建主从复制架构？（三种方式）1、从服务器的配置文件 1replicaof &lt;masterip&gt; &lt;masterport&gt; 2、启动 redis-server启动命令--replicaof &lt;masterip&gt; &lt;masterport&gt; 3、客户端命令 启动多个 Redis实例后，直接通过客户端执行命令：replicaof &lt;masterip&gt; &lt;masterport&gt;，则该 Redis 实例成为从节点。 主从第一次全量复制三个阶段：建立连接、主库同步数据给从库、发送新的写命令给从库。 第一阶段建立连接从库会和主库建立连接，从库执行replicaof 并发送psync 命令并告诉主库即将进行同步，主库确认回复后，主从库间就开始同步了。 从节点内部维护了两个字段，masterhost 和 masterport，用于存储主节点的 IP 和 port 信息。 从库执行 replicaof 并发送 psync 命令，表示要执行数据同步，主库收到命令后根据参数启动复制。命令包含了主库的 runID 和 复制进度 offset 两个参数。 runID：每个 Redis 实例启动都会自动生成一个 唯一标识 ID，第一次主从复制，还不知道主库 runID，参数设置为 「?」。 offset：第一次复制设置为 -1，表示第一次复制，记录复制进度偏移量。 主库收到psync命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度offset，返回给从库。从库收到响应后，会记录下这两个参数。 FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。 第二阶段发送同步数据master 执行 bgsave命令生成 RDB 文件，并将文件发送给从库，同时主库为每一个 slave 开辟一块 replication buffer 缓冲区记录从生成 RDB 文件开始收到的所有写命令。 从库收到 RDB 文件后保存到磁盘，并清空当前数据库的数据，再加载 RDB 文件数据到内存中。 为什么清空从库的数据？因为从库在通过 replcaof命令开始和主库同步前可能保存了其他数据，防止主从数据之间的影响。 第三阶段发送新命令到从库replication buffer 缓冲区存放数据 1）master 执行 bgsave产生 RDB 的期间的写操作； 2）master 发送rdb 到 slave 网络传输期间的写操作； 3）slave load rdb 文件把数据恢复到内存的期间的写操作。 replication buffer 太小会引发的问题？replication buffer 由 client-output-buffer-limit slave 设置，当这个值太小会导致主从复制连接断开。 1）当 master-slave 复制连接断开，master 会释放连接相关的数据。replication buffer 中的数据也就丢失了，此时主从之间重新开始复制过程。 2）还有个更严重的问题，主从复制连接断开，导致主从上出现重新执行 bgsave 和 rdb 重传操作无限循环。 当主节点数据量较大，或者主从节点之间网络延迟较大时，可能导致该缓冲区的大小超过了限制，此时主节点会断开与从节点之间的连接； 这种情况可能引起全量复制 -&gt; replication buffer 溢出导致连接中断 -&gt; 重连 -&gt; 全量复制 -&gt; replication buffer 缓冲区溢出导致连接中断……的循环。 具体详情：[top redis headaches for devops – replication buffer] 因而推荐把 replication buffer 的 hard/soft limit 设置成 512M。 主从库复制为何不使用 AOF 呢？相比 RDB 来说，丢失的数据更少。原因如下： RDB 文件是二进制文件，网络传输 RDB 和写入磁盘的 IO 效率都要比 AOF 高。 从库进行数据恢复的时候，RDB 的恢复效率也要高于 AOF。 增量复制在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。 从 Redis 2.8开始，网络断了之后，主从库会采用增量复制的方式继续同步。 增量复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。 repl_backlog_buffer 缓冲区断开重连增量复制的实现奥秘就是 repl_backlog_buffer 缓冲区，不管在什么时候 master 都会将写指令操作记录在 repl_backlog_buffer 中，因为内存有限，repl_backlog_buffer 是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容。 master 使用 master_repl_offset记录自己写到的位置偏移量，slave 则使用slave_repl_offset记录已经读取到的偏移量。 master 收到写操作，偏移量则会增加。从库持续执行同步的写指令后，在 repl_backlog_buffer 的已复制的偏移量slave_repl_offset 也在不断增加。 正常情况下，这两个偏移量基本相等。在网络断连阶段，主库可能会收到新的写操作命令，所以 master_repl_offset会大于 slave_repl_offset。 repl_backlog_buffer 太小的话从库还没读取到就被 Master 的新写操作覆盖了咋办？一旦被覆盖就会执行全量复制。我们可以调整 repl_backlog_size 这个参数用于控制缓冲区大小。计算公式： 1repl_backlog_buffer = second * write_size_per_second second：从服务器断开重连主服务器所需的平均时间； write_size_per_second：master 平均每秒产生的命令数据量大小（写命令和数据大小总和）； 例如，如果主服务器平均每秒产生 1 MB 的写数据，而从服务器断线之后平均要 5 秒才能重新连接上主服务器，那么复制积压缓冲区的大小就不能低于 5 MB。 为了安全起见，可以将复制积压缓冲区的大小设为2 * second * write_size_per_second，这样可以保证绝大部分断线情况都能用部分重同步来处理。 基于长连接的命令传播当主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，使用长连接的目的就是避免频繁建立连接导致的开销。 在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING 和 REPLCONF ACK。 主-&gt;从：PING 每隔指定的时间，主节点会向从节点发送 PING 命令，这个 PING 命令的作用，主要是为了让从节点进行超时判断。 从-&gt;主：REPLCONF ACK 在命令传播阶段，从服务器默认会以每秒一次的频率，向主服务器发送命令： 1REPLCONF ACK &lt;replication_offset&gt; 其中 replication_offset 是从服务器当前的复制偏移量。发送 REPLCONF ACK 命令对于主从服务器有三个作用： 检测主从服务器的网络连接状态。 辅助实现 min-slaves 选项。 检测命令丢失, 从节点发送了自身的 slave_replication_offset，主节点会用自己的 master_replication_offset 对比，如果从节点数据缺失，主节点会从 repl_backlog_buffer缓冲区中找到并推送缺失的数据。注意，offset 和 repl_backlog_buffer 缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。 从节点根据当前状态，发送 psync命令给 master： 如果从节点从未执行过 replicaof ，则从节点发送 psync ? -1，向主节点发送全量复制请求； 如果从节点之前执行过 replicaof 则发送 psync &lt;runID&gt; &lt;offset&gt;,runID是上次复制保存的主节点 runID，offset 是上次复制截至时从节点保存的复制偏移量。 主节点根据接受到的psync命令和当前服务器状态，决定执行全量复制还是部分复制： runID 与从节点发送的runID 相同，且从节点发送的 slave_repl_offset之后的数据在 repl_backlog_buffer缓冲区中都存在，则回复 CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可； runID 与从节点发送的runID不同，或者从节点发送的 slave_repl_offset 之后的数据已不在主节点的 repl_backlog_buffer缓冲区中 (在队列中被挤出了)，则回复从节点 FULLRESYNC &lt;runid&gt; &lt;offset&gt;，表示要进行全量复制，其中runID 表示主节点当前的 runID，offset 表示主节点当前的 offset，从节点保存这两个值，以备使用。 一个从库如果和主库断连时间过长，造成它在主库 repl_backlog_buffer的 slave_repl_offset 位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。 replication buffer 和 repl_backlog replication buffer 对应于每个 slave，通过 config set client-output-buffer-limit slave设置。 repl_backlog_buffer是一个环形缓冲区，整个 master 进程中只会存在一个，所有的 slave 公用。repl_backlog 的大小通过 repl-backlog-size参数设置，默认大小是 1M，其大小可以根据每秒产生的命令、（master 执行 rdb bgsave） +（ master 发送 rdb 到 slave） + （slave load rdb文件）时间之和来估算积压缓冲区的大小，repl-backlog-size 值不小于这两者的乘积。 总的来说，replication buffer 是主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer，而 repl_backlog_buffer 是为了支持从库增量复制，主库上用于持续保存写操作的一块专用 buffer。 repl_backlog_buffer是一块专用 buffer，在 Redis 服务器启动后，开始一直接收写操作命令，这是所有从库共享的。主库和从库会各自记录自己的复制进度，所以，不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步。 主从架构应用问题主从复制的场景下，从节点会删除过期数据么？为了主从节点的数据一致性，从节点不会主动删除数据。我们知道 Redis 有两种删除策略： 惰性删除：当客户端查询对应的数据时，Redis 判断该数据是否过期，过期则删除。 定期删除：Redis 通过定时任务删除过期数据。 客户端通过从节点读取数据会不会读取到过期数据？Redis 3.2开始，通过从节点读取数据时，先判断数据是否已过期。如果过期则不返回客户端，并且删除数据。 单机内存大小限制如果Redis 单机内存达到 10GB，一个从节点的同步时间在几分钟的级别；如果从节点较多，恢复的速度会更慢。如果系统的读负载很高，而这段时间从节点无法提供服务，会对系统造成很大的压力。 如果数据量过大，全量复制阶段主节点 fork + 保存 RDB 文件耗时过大，从节点长时间接收不到数据触发超时，主从节点的数据同步同样可能陷入全量复制-&gt;超时导致复制中断-&gt;重连-&gt;全量复制-&gt;超时导致复制中断……的循环。 此外，主节点单机内存除了绝对量不能太大，其占用主机内存的比例也不应过大：最好只使用 50% - 65% 的内存，留下 30%-45% 的内存用于执行bgsave 命令和创建复制缓冲区等。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://duanjiaojiao316.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://duanjiaojiao316.github.io/tags/redis/"}]},{"title":"有关回文的编程题总结","slug":"有关回文的编程题总结","date":"2021-03-11T13:09:05.000Z","updated":"2021-04-20T07:44:33.823Z","comments":true,"path":"2021/03/11/有关回文的编程题总结/","link":"","permalink":"https://duanjiaojiao316.github.io/2021/03/11/%E6%9C%89%E5%85%B3%E5%9B%9E%E6%96%87%E7%9A%84%E7%BC%96%E7%A8%8B%E9%A2%98%E6%80%BB%E7%BB%93/","excerpt":"","text":"有关回文的编程题总结 题目一：给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。 解法一：中心扩展法 使用中心扩展法：由于回文字符串有可能是偶数个字符，也有可能是奇数个字符，所以回文子串的中心有可能是一个字符也有可能是字符中间位置。所以需要遍历字符串s的左右中心点，判断是否为回文子串。 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.Scanner;public class Solution&#123; public static int expandAroundCenter(String s, int left, int right)&#123; int l = left; int r = right; //由中心向两边延伸，两端字符相同继续延伸，不相同则返回回文子串的长度。 while(l &gt;= 0 &amp;&amp; r &lt; s.length() &amp;&amp; s.charAt(l)==s.charAt(r))&#123; l--; r++; &#125; return r-l-1; &#125; public static String longestPalindrome(String s)&#123; if(s.length() &lt; 1 || s == null)&#123; return &quot;&quot;; &#125; int start = 0; int end = 0; for(int i = 0; i &lt; s.length(); i++)&#123; int len1 = expandAroundCenter(s, i, i) ;//回文子串中心为i位置的字符 int len2 = expandAroundCenter(s, i, i+1);//回文中心在i位置字符和i+1位置字符之间 int len = Math.max(len1, len2);//求出两种中心状态下最长的字符串长度 if(len &gt; end-start)&#123; //求出回文子串的首位部分 start = i - (len-1)/2; end = i + len/2; &#125; &#125; return s.substring(start,end + 1); &#125; public static void main(String[] args) &#123; Scanner input = new Scanner (System.in); String s = input.nextLine(); System.out.println(longestPalindrome(s)); &#125;&#125; 解法二：暴力算法 暴力算法 暴力法将选出所有子字符串可能的开始和结束位置，并检验它是不是回文 123456789101112131415161718192021222324public class Solution &#123; public String longestPalindrome(String s)&#123; String result = &quot;&quot;; for (int i = 0; i &lt; s.length(); i++) &#123; for (int j = i+1; j &lt; s.length(); j++) &#123; String temp1 = s.substring(i,j); String temp2 = reverse(temp1); if(temp1.equals(temp2) &amp;&amp; result.length()&lt;temp1.length())&#123; result = temp1; &#125; &#125; &#125; return result; &#125; /** * 使用StringBuilder或者StringBuffer的reverse方法实现String的反转 * @param s * @return s反转后的字符串 */ public String reverse(String s)&#123; return new StringBuilder(s).reverse().toString(); &#125;&#125; 解法三：动态规划 123456789101112131415161718192021public class Solution2 &#123; public String longestPalindrome(String s) &#123; boolean [][] p = new boolean[s.length()][s.length()]; String maxPalindrome = &quot;&quot;; for (int i = 0; i &lt; s.length(); i++) &#123; for (int start = 0; start &lt; s.length(); start++) &#123; int end = start + i; if (end &gt;= s.length())&#123; break; &#125; //i==0和i==1是初始化单个回文字符串和两个字符的回文字符串 p[start][end] = (i == 0 || i == 1 || p[start + 1][end - 1]) &amp;&amp; s.charAt(start) == s.charAt(end); if (p[start][end] &amp;&amp; i &gt; maxPalindrome.length()) &#123; maxPalindrome = s.substring(start, end + 1); &#125; &#125; &#125; return maxPalindrome; &#125;&#125; 题目二：判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。 要考虑负数，个位数是0的数字直接就不是回文数字 我们获取数字的一半，反转后半部分的一半，如果和前半部分相似就确定为回文数字 关于奇数位的数字，通过最后partlyNumber/10==x;除以10将中间的位数去掉，因为中间的数字一定等于其本身，不影响其是不是回文数。 123456789101112131415public class Solution &#123; public boolean isPalindrome(int x) &#123; if(x &lt; 0||(x!=0&amp;&amp; x%10==0))&#123; return false; &#125;else&#123; int partlyNumber = 0; while (x &gt; partlyNumber)&#123; partlyNumber = partlyNumber*10+x%10; x/= 10; &#125; return partlyNumber==x||partlyNumber/10==x; &#125; &#125;&#125;","categories":[{"name":"基础算法","slug":"基础算法","permalink":"https://duanjiaojiao316.github.io/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"回文","slug":"回文","permalink":"https://duanjiaojiao316.github.io/tags/%E5%9B%9E%E6%96%87/"}]},{"title":"关于YARN——基础知识","slug":"关于YARN基础知识","date":"2021-03-09T13:56:09.000Z","updated":"2021-04-20T07:44:33.816Z","comments":true,"path":"2021/03/09/关于YARN基础知识/","link":"","permalink":"https://duanjiaojiao316.github.io/2021/03/09/%E5%85%B3%E4%BA%8EYARN%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"1、什么是YARN YARN是Hadoop的集群资源管理系统，在Hadoop 2被引入，为了盖上MapReduce的实现。YARN提供请求和使用资源的API，这些API向用户隐藏了资源管理的细节。一些分布式计算框架MapReduce、spark运行在YARN和存储层HDFS/HBase上。 集群层次框架： Upper Application Pig/Hive/Crunch Application MapReduce/Spark/Tez /… Compute YARN Storage HDFS and HBase YARN通过两类长期运行的守护进程提供自己的服务 资源管理器：管理集群上资源使用 节点管理器：运行在集群的所有节点上，启动和监控容器 container 容器：执行job进程，容器有资源限制(内存，CPU等)，具体容器取决于YARN配置 2、YARN的运行机制： 首先客户端请求RM，运行一个application master RM找到可以在容器中启动application master的NM，在NM启动容器，运行application master 容器通过心跳机制向RM请求运行资源(内存和CPU) application master运行起来之后需要做什么依赖于客户端传递的应用 a. 简单地运算后直接返回结果给客户端 b. 请求更多容器进行分布式计算 YARN通信手段： YARN不提供任何手段用于应用各部分(客户端/application master/进程)通信，使用**具体应用的远程通信机制(如Hadoop的RPC层)**来向客户端返回状态和结果 YARN资源请求的灵活性： 指定每个容器的计算机资源数量(内存和CPU) 容器的本地限制要求，可以申请指定节点，机架或集群中任意位置(包含集群外)的容器 可以在运行中的任意时刻请求资源，可以一开始请求所有资源(Spark)；也可以动态申请，随着应用程序的运行而动态地请求(MapReduce先请求Map任务资源，后请求Reduce任务资源） 应用生命期-三种模型 这里的应用指的是application master，用来处理job的YARN的应用进程 一个用户作业对应一个application master（MapReduce） 作业的每个工作流或者每个用户对话对应一个application master 效率高，容器可以在作业之间重用，可能缓存中间数据，Spark使用这种模型 多个用户共享一个长期运行的应用 这种application master作为协调者身份运行，一个always on的application master，则无需启动新的application master，低开销，低响应延迟 3、YARN的调度 YARN调度器根据既定策略为应用分配资源，由于调度难题没有所谓”最好“的策略，YARN提供多种调度器和可配置策略。 YARN三种调度器 1）FIFO调度器（FIFO Scheduler）：应用放置在一个队列中，按照作业提交的顺序运行 2）容量调度器（Capacity Scheduler）：独立的专门队列保证小作业也可以提交后就启动，队列容量是专门保留的，以整个集群的利用率为代价，与FIFO比，大作业执行的时间要长 3）公平调度器（Fair Scheduler）：不需要预留一定的资源，调度器会在所有的运行的作业之间动态平衡资源，第一个（大）作业启动时，他是唯一运行的作业所以获得集群中的所有资源，当第二个作业启动时，它被分配到集群的一半资源，每个作业都能公平共享资源。 第二个作业从启动到获得资源会有一定的时间滞后，它必须等第一个大作业使用的容器用完并释放资源，小作业结束并且不再使用资源之后，大作业将回去再次使用全部的资源。最终的效果：既得到了较高的集群利用率，又能保证小作业及时完成 容量调度器配置 容量调度器允许多个组织共享一个Hadoop集群，每个组织可以分配到全部集群资源的一部分。每个组织有一个专门的队列，每个队列被配置使用集群的一定资源。队列也可以按照层次进一步划分，这样每个组织内部的不同用户能共享该组织队列的全部资源，在一个队列中采取FIFO调度策略。 如果队列中有多个作业，队列资源不够，此时如果其他队列有空闲的资源，容量调度器会把空闲的资源分配给队列中的作业，会超出队列容量。这种成为弹性队列。 正常操作时不会出现抢占队列资源，如果队列资源不够用，需要等其他队列释放容器资源。 为队列设置自最大容量限制，这样队列就不会过多的侵占其他队列的容量，这种方法以牺牲弹性队列为代价防止过多侵占。 假设一个队列层次 root队列下，prod和dev队列分别占40%和60%的容量。配置文件如下 12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot;?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt; &lt;value&gt;prod,dev&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.dev.queues&lt;/name&gt; &lt;value&gt;eng,science&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.prod.capacity&lt;/name&gt; &lt;value&gt;40&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.dev.capacity&lt;/name&gt; &lt;value&gt;60&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.dev.maximum-capacity&lt;/name&gt; &lt;value&gt;75&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.dev.eng.capacity&lt;/name&gt; &lt;value&gt;50&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.capacity.root.dev.science.capacity&lt;/name&gt; &lt;value&gt;50&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; dev队列最大容量设置为75%，其实prod队列是空闲的，dev队列也不会占用全部的集群资源。prod队列使用的资源占比总能达到25%。由于没有对eng和science队列的最大容量进行限制，其中一个队列中的作业可能会占用dev队列中的所有资源（相当于全部集群资源的75%），而prod队列可以占用集群的全部资源。 通过mapreduce.job.queuename属性设置应用的队列，不指定应用将放在名为“default”的默认队列中。 在容量调度器，队列的名字是队列层次的最后一部分，完整队列层次名不会被识别。 prod和dev是合法的队列名，root.dev.eng作为队列名无效。 公平调度器配置 假如有A和B两个用户，分别拥有队列queueA和队列queueB，A启动一个作业，B此时没有需求，A会分到队列的全部资源，当A还在运行，B启动第一个作业，将占用一半资源，此时如果B启动第二个作业，其他的作业都还在运行，第二个作业将和B共享资源，获取队列B的一半资源。 1、启动公平调度器 公平调度器的使用由属性yarn.resourcemanager.scheduler.class 的设置所决定。默认是使用 Capacity Scheduler (尽管在一些Hadoop分布式项目， 如CDH中是默认使用 Fair Scheduler)，如果要使用 Fair Scheduler，需要修改yarn-site.xml 文件。 123456&lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt; &lt;value&gt; org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler &lt;/value&gt;&lt;/property&gt; 2、队列配置 通过一个名为fair-scheduler.xml的分配文件对 Fair Scheduler 进行配置， 该文件位于类路径下。(可以通过设置属性yarn.scheduler.fair.allocation.file来修改文件名) 。当没有该分配文件时，Fair Scheduler的工作策略同先前所描述的一样：每个应用放置在一个以用户名命名的队列中，队列是在用户提交第一个应用时动态创建的。 通过分配文件可以为每个队列进行配置。这样可以对 Fair Scheduler 支持的层次队列进行配置。 例如，可以像为Capacity Scheduler所做的那样，使用分配文件定义 prod 和 dev。 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot;?&gt;&lt;allocations&gt; &lt;defaultQueueSchedulingPolicy&gt;fair&lt;/defaultQueueSchedulingPolicy&gt; &lt;queue name=&quot;prod&quot;&gt; &lt;weight&gt;40&lt;/weight&gt; &lt;schedulingPolicy&gt;fifo&lt;/schedulingPolicy&gt; &lt;/queue&gt; &lt;queue name=&quot;dev&quot;&gt; &lt;weight&gt;60&lt;/weight&gt; &lt;queue name=&quot;eng&quot; /&gt; &lt;queue name=&quot;science&quot; /&gt; &lt;/queue&gt; &lt;queuePlacementPolicy&gt; &lt;rule name=&quot;specified&quot; create=&quot;false&quot; /&gt; &lt;rule name=&quot;primaryGroup&quot; create=&quot;false&quot; /&gt; &lt;rule name=&quot;default&quot; queue=&quot;dev.eng&quot; /&gt; &lt;/queuePlacementPolicy&gt;&lt;/allocations&gt; 3、队列放置 使用基于规则的系统确定job队列放置，匹配对应的用户队列直到使用default队列 直接就使用default，所有job公平分配 第一条规则， specified， 表示把应用放进所指明的队列中， 如果没有指明，或如果所指明的队列不存在，则规则不匹配，继续尝试下一条规则。 primary Group规则会试着把应用放在以用户的主Unix组名命名的队列中，如果没有这样的队列， 则继续尝试下一条规则而不是创建队列。 Defahult规则是 一条兜底规则， 当前述规则都不匹配时， 将启用该条规则， 把应用放进 dev.eng 队列中。","categories":[],"tags":[]},{"title":"VAEs变分自编码器","slug":"VAEs变分自编码器","date":"2021-03-09T02:30:11.000Z","updated":"2021-04-20T07:44:33.812Z","comments":true,"path":"2021/03/09/VAEs变分自编码器/","link":"","permalink":"https://duanjiaojiao316.github.io/2021/03/09/VAEs%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8/","excerpt":"","text":"AE自编码器 首先了解自编码器AE。Auto Encoder是一种自监督的神经网络，它学习如何将输入编码为更低的维数，然后再次解码和重构数据以尽可能有效地接近输入。 Autoencoder由3个部分组成: 编码器，将输入数据编码为较低维表示的层。 压缩层，包含编码/压缩表示的最低维数的层。也被称为瓶颈。 译码器，学会解码或重新构造编码表示到数据的层接近输入数据。 为了学习最好的编码和解码，自编码器的目标是使重构误差最小化，重构误差基本上是重构数据和输入数据之间的差值。L2(平方)重构损失 RecontructedLoss=∣∣Input−ReconstructedOutput∣∣2Recontructed Loss = ||Input-Reconstructed Output||^2 RecontructedLoss=∣∣Input−ReconstructedOutput∣∣​2​​ 自动编码器功能: 去噪:为了使自动编码器学会去噪图像，我们使用一个损坏或有噪声的图像作为输入，然后修改重建损失，使重建输出与原始干净的图像之间的差异最小，而不是损坏的输入。编码器的目标是只编码有用的特征，因此，随机噪声应在重建过程中丢失。 降维:通过使用输出层比输入层有更少维数的“不完全”自动编码器，自动编码器能够在更低维数的情况下非线性地表示数据，这与有限的线性变换的PCA(主成分分析)方法形成对比。 使用Autoencoder生成新数据背后的想法是通过修改编码的数据(潜在向量)，我们应该能够得到不同于输入的数据。为了简化这一点，让我们想象一下这样的场景:您试图将一些图像编码为2d编码，如下所示。 为了生成一个新的图像，我们可以简单地从上面的潜在空间中采样一个点。例如，如果我们对狗和鸟之间的一个点进行采样，我们可能能够得到一张鸟和狗杂交的图像，或者一种新的动物。 然而，编码器生成的向量(编码)往往是不规则的、无组织的或不可解释的，因为它的目的只是重构尽可能相似的输入，而本身没有任何约束。因此，它不关心如何编码数据，只要它能完美地重构输入。 不规则潜在空间的随机点可能会产生无意义的结果 由于自动编码器模型可以自由地编码潜在向量，潜在空间可能会有很多区域，其中的空白区域会产生随机/不可解释的输出，如图中的空白区域所示。相反，我们希望具有有意义输出的潜在空间区域是连续的，而不是像下图那样是分开的，这样可以方便地在不同属性之间进行插值。 要获得具有良好性质的潜在空间，必须正则化返回的分布。因此，可变自动编码器试图通过添加调节器来解决这一问题，避免过拟合，并确保潜在空间具有良好的连续性特征，使生成过程成为可能。 VAEs变分自编码器 可变自动编码器以概率方式(分布)编码输入的潜在属性，而不是像普通的自动编码器那样以确定性方式(单值)编码。 想象一下上面的例子，自动编码器将图像编码为表示照片中的微笑的潜在属性(注意，在真实的训练中，我们不知道每个属性实际表示什么)。普通的自动编码器将为潜属性提供一个值，但变分自动编码器将潜属性存储为属性的概率分布，如上面的右图所示。 现在，由于我们有了每个属性的概率分布，我们可以简单地从分布中抽取任何值来生成一个新的输出。 我知道VAE将潜在变量存储为概率分布时我首先想到的问题是如何存储一个分布。我们假设潜在分布总是高斯分布。高斯分布可以很容易地用两个值来描述，即均值和方差或标准差(您可以从方差计算出标准差)。 数学基础 熵Entropy 假设p(x)是一个分布函数，满足在x上的积分为1，那么p(x)的熵定义为H(p(x))，简写H§。 H(p)=∫p(x)log1p(x)dxH(p) = \\int p(x)log\\frac{1}{p(x)}dx H(p)=∫p(x)log​p(x)​​1​​dx 分布函数越分散熵越大，分布函数越集中熵越小。 交叉熵Cross-Entropy 假设两个分布函数p(x)和q(x)，那么交叉熵定义为H(p,q)。 H(p,q)=∫p(x)1q(x)dxH(p,q) = \\int p(x)\\frac{1}{q(x)}dx H(p,q)=∫p(x)​q(x)​​1​​dx 交叉熵的小大评价了两个分布函数的相似与否。交叉熵小分布相似，交叉熵大分布不相似。 KL散度 假设p(x)和q(x)是两个分布函数，KL散度的小大评价了两个分布函数的相似与否，并且考虑了p(x)分布的信息量 KL(p,q)=H(p,q)−H(p)KL(p,q) = H(p,q)-H(p) KL(p,q)=H(p,q)−H(p) VAEs的损失函数： L(x,\\widehat{x}) + KL(q,p) 为什么同时使用重构损失和kl散度? 在讨论了kl散度之后，为什么我们仍然在整体损失函数中使用重构损失呢?为了理解损失函数背后的原理，以及重构损失和KL散度对潜在空间的影响。让我们看看下面的图表。 只使用重构损失时潜在空间内部将有空隙，不真正代表任何有意义的数据。因此，可变自动编码器使用分布而不是最小的差异与kl -散度。但是，如果我们只专注于用我们的kl -散度损失项模拟先验分布，我们将会将每个单位描述为单位正态分布，而不能描述原始数据。 因此，通过使用两者的组合，我们将获得一个平衡，即拥有一个接近先验分布但仍然描述输入的某些特征的潜在表示。","categories":[],"tags":[]},{"title":"初始Kafka","slug":"初始Kafka","date":"2021-01-08T13:56:47.000Z","updated":"2021-04-20T07:44:33.821Z","comments":true,"path":"2021/01/08/初始Kafka/","link":"","permalink":"https://duanjiaojiao316.github.io/2021/01/08/%E5%88%9D%E5%A7%8BKafka/","excerpt":"","text":"1、Kafka的定义 首先了解Kafka是什么，在哪些地方扮演着什么角色？ kafka是一个多分区多副本基于ZooKeeper协调的发布/订阅模式分布式消息系统，具有高吞吐量，可持久化，可水平扩展，支持流数据处理特性，kafka主要用于：消息系统，存储系统，流式处理平台。 Kafka与其他的消息中间件类似，具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性等功能，同时还实现了消息顺序性保障以及消息回溯功能。 Kafka在存储系统，将消息持久化到磁盘，相比于其他的内存存储的系统降低数据丢失的风险，主要得益于Kafka的持久化功能多副本机制。 在流式处理平台，为流式处理框架提供可靠的数据来源，提供流式处理类库。 2、Kafka的体系架构 Kafka主要由三个部分：生产者Producer、消费者Consumer、服务代理节点Broker。 生产者创建消息，将消息发送到Kafka；消费者从Kafka拉取消息，接收消息；broker是Kafka的服务节点，如果Kafka中只有一个broker，也可以看做Kafka服务器。多个broker组成Kafka集群。 Kafka中以主题为单元进行存储，一个主题可以划分为多个分区，一个分区只能属于一个主题，分区在存储层面可以看做Log日志文件，把消息附加到分区中会分配到一个offset偏移量，Kafka通过偏移量保证消息的顺序性。注意offset不跨越分区。所以Kafka中保证分区内消息有序而不是主题有序。 从图中可以看出分区副本，Kafka引入分区的多副本机制，可以提高容错能力，但是同一时刻不同副本之间的消息并非完全相同，副本之间是一主多从的关系，leader负责读写请求，follower副本只负责和leader消息同步。不同副本处于不同的broker，如果leader出现故障，可以从follower中重新选举新的leader。 在分区中所有的副本统称为AR，与leader保持一定程度同步的副本组成ISR，一定程度表示可以忍受的容错范围，这个指标可以通过参数指定，与leader具有过多之后的副本组成OSR。所以AR=ISR+OSR 同时leader负责维护和跟踪ISR中所有副本的滞后状态，如果follower滞后较多，leader会将他从ISR中剔除，如果OSR中副本没有较多的滞后，会把它转移到ISR中。如果leader发生故障，只会从ISR中选举leader，OSR中的follower没有机会选举为新的leader。 为了进一步了解ISR和OSR，需要了解HW和LEO。 HW（ High Watermark）高水位。 LEO（Log End Offset）当前日志下一条消息的offset。 LEO是分区中最后一条消息offset的值+1，ISR集合中最小的LEO为HW，消费者只能消费HW之前的消息。","categories":[{"name":"后端","slug":"后端","permalink":"https://duanjiaojiao316.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"大数据","slug":"后端/大数据","permalink":"https://duanjiaojiao316.github.io/categories/%E5%90%8E%E7%AB%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://duanjiaojiao316.github.io/tags/Kafka/"}]},{"title":"BFS算法框架-解开密码锁的最少次数","slug":"BFS算法框架-解开密码锁的最少次数","date":"2020-12-15T12:25:17.000Z","updated":"2021-05-11T07:46:58.340Z","comments":true,"path":"2020/12/15/BFS算法框架-解开密码锁的最少次数/","link":"","permalink":"https://duanjiaojiao316.github.io/2020/12/15/BFS%E7%AE%97%E6%B3%95%E6%A1%86%E6%9E%B6-%E8%A7%A3%E5%BC%80%E5%AF%86%E7%A0%81%E9%94%81%E7%9A%84%E6%9C%80%E5%B0%91%E6%AC%A1%E6%95%B0/","excerpt":"","text":"遍历所有的密码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 密码锁向上拨动String plusOne(String secret, int i) &#123; char[] ch = secret.toCharArray(); if(ch[j] == &#x27;9&#x27;)&#123; ch[j] = &#x27;0&#x27;; &#125; else &#123; ch[j] += 1; &#125; return String(ch);&#125;// 密码锁向上拨动String downOne(String secret, int i) &#123; char[] ch = secret.toCharArray(); if(ch[j] == &#x27;0&#x27;)&#123; ch[j] = &#x27;9&#x27; &#125; else &#123; ch[j] -= 1; &#125; return String(ch)&#125;// 打印出所有的密码组合void BFS(String target) &#123; // 队列 Queue[String] queue = new Linkedlist&lt;&gt;(); queue.offer(&quot;0000&quot;); while(!queue.empty())&#123; int size = queue.size; for(int i = 0; i &lt; size; i++) &#123; String cur = queue.poll(); // 这里判断是否达到终点 System.out.println(cur); for (int j = 0; j &lt; 4; j++) &#123; String up = plusOne(cur, j); String down = downOne(cur, j); q.offer(up); q.offer(down); &#125; &#125; // 这里可以进行步长计算 &#125; return&#125; 以上代码由于没有终止条件，0000拨动成0001，同时0001也可以拨动成0000 加入死亡密码和终止密码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051int BFS(String target, String[] deadends) &#123; // 死亡密码 Set[String] deadSecrets = new HashSet&lt;&gt;(); for(String d: deadends) &#123; deadSecrets.add(d); &#125; Set[String] visited = new HashSet&lt;&gt;(); // 队列 Queue[String] queue = new Linkedlist&lt;&gt;(); // 初始化步长 int step = 0; queue.offer(&quot;0000&quot;); visited.add(&quot;0000&quot;); while(!queue.empty())&#123; int size = queue.size(); for (int i = 0; i &lt; size; i++) &#123; String cur = queue.poll(); // 判断是否是死亡密码 if (deadends.contains(cur)) &#123; continue; &#125; // 这里判断是否达到终点 if (cur.equal(target)) &#123; return step; &#125; System.out.println(cur); for (int j = 0; j &lt; 4; j++) &#123; String up = plusOne(cur, j); if (!visited.contains(up))&#123; q.offer(up); visited.add(up); &#125; String down = downOne(cur, j); if (!visited.contains(up))&#123; q.offer(down); visited.add(down); &#125; &#125; &#125; step ++; // 这里可以进行步长计算 &#125; //如果遍历都没有查找到目标，证明没有办法到目标密码 return -1;&#125; 传统的 BFS 框架就是从起点开始向四周扩散，遇到终点时停止；而双向 BFS 则是从起点和终点同时开始扩散，当两边有交集的时候停止。 不过，双向 BFS 也有局限，因为你必须知道终点在哪里。比如二叉树最小高度的问题，一开始根本就不知道终点在哪里，也就无法使用双向 BFS；但是密码锁的问题，可以使用双向 BFS 算法来提高效率 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int BFS(String target,String[] deadends) &#123; // 死亡密码 Set[String] deadSecrets = new HashSet&lt;&gt;(); for(String d: deadends) &#123; deadSecrets.add(d); &#125; Set[String] visited = new HashSet&lt;&gt;(); // 队列 Set[String] queue1 = new HashSet&lt;&gt;(); Set[String] queue2 = new HashSet&lt;&gt;(); // 初始化步长 int step = 0; queue1.add(&quot;0000&quot;); queue2.add(target); visited.add(&quot;0000&quot;); visited.add(target); while(!queue1.empty() &amp;&amp; !queue2.empty()) &#123; // 哈希集合在遍历的过程中不能修改，用 temp 存储扩散结果 Set&lt;String&gt; temp = new HashSet&lt;&gt;(); /* 将 q1 中的所有节点向周围扩散 */ for (String cur : q1) &#123; /* 判断是否到达终点 */ if (deadSecrets.contains(cur)) continue; if (q2.contains(cur)) return step; visited.add(cur); /* 将一个节点的未遍历相邻节点加入集合 */ for (int j = 0; j &lt; 4; j++) &#123; String up = plusOne(cur, j); if (!visited.contains(up)) temp.add(up); String down = downOne(cur, j); if (!visited.contains(down)) temp.add(down); &#125; &#125; // 增加步长 step ++; // 这里交换queue1和queue2 下一个循环就会扩展queue2相邻的密码 queue1 = queue2; queue2 = temp; &#125; return -1;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://duanjiaojiao316.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"BFS（广度优先搜索）","slug":"BFS（广度优先搜索）","permalink":"https://duanjiaojiao316.github.io/tags/BFS%EF%BC%88%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%EF%BC%89/"}]},{"title":"算法套路框架","slug":"算法套路框架","date":"2020-12-14T08:23:00.000Z","updated":"2021-04-20T07:44:33.823Z","comments":true,"path":"2020/12/14/算法套路框架/","link":"","permalink":"https://duanjiaojiao316.github.io/2020/12/14/%E7%AE%97%E6%B3%95%E5%A5%97%E8%B7%AF%E6%A1%86%E6%9E%B6/","excerpt":"","text":"1234567891011121314151617181920212223242526272829// 计算从起点 start 到终点 target 的最近距离int BFS(Node start, Node target) &#123; Queue&lt;Node&gt; q; // 核心数据结构 队列 Set&lt;Node&gt; visited; // 避免走回头路 已访问过点加入 visited q.offer(start); // 将起点加入队列 visited.add(start); int step = 0; // 记录扩散的步数 while (q not empty) &#123; int sz = q.size(); /* 将当前队列中的所有节点向四周扩散 */ for (int i = 0; i &lt; sz; i++) &#123; Node cur = q.poll(); /* 划重点：这里判断是否到达终点 */ if (cur is target) return step; /* 将 cur 的相邻节点加入队列 */ // cur.adj() 表示与但钱节点相邻的节点 for (Node x : cur.adj()) if (x not in visited) &#123; q.offer(x); visited.add(x); &#125; &#125; /* 划重点：更新步数在这里 */ step++; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://duanjiaojiao316.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法 BFS（广度优先搜索）","slug":"算法-BFS（广度优先搜索）","permalink":"https://duanjiaojiao316.github.io/tags/%E7%AE%97%E6%B3%95-BFS%EF%BC%88%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%EF%BC%89/"}]},{"title":"高性能MySQL","slug":"高性能MySQL","date":"2020-11-29T14:31:44.000Z","updated":"2021-04-20T07:44:33.824Z","comments":true,"path":"2020/11/29/高性能MySQL/","link":"","permalink":"https://duanjiaojiao316.github.io/2020/11/29/%E9%AB%98%E6%80%A7%E8%83%BDMySQL/","excerpt":"","text":"高性能MySQL 高性能索引 使用ORM对象关系映射工具也需要关注索引，关于ORM工具，不论多复杂都不能完成完美的查询优化。 B-Tree索引 所有的值按顺序存储，每个叶子页到根的距离相同，避免了全表扫描搜索。从索引的根节点开始进行搜索，根节点的槽存放指向子节点的指针，存储引擎根据这些指针向下层查询。通过子节点的值和要查询数据的值进行比较找到合适的指针指向下一层子节点。这些指针定义了子节点的值的上限和下限。叶子节点的指针指向的是被索引的数据，不是其他节点页。 B-Tree对索引列是顺序组织存储的，适合查找范围数据。 在定义B-Tree索引时，索引列多于一个，索引列的顺序与key(lastname,firstname,dob)中的顺序无关，依据的顺序是CREATE TABLE语句中定义索引时列的顺序。 查询类型 全值匹配：查询姓名为xxx xxx，出生日期为yyyy-mm-dd的人 匹配最左前缀： 查询姓为xxx的人 匹配列前缀： 查询姓以J开头的人 匹配范围值： 查询姓在某两个值之间的人 精确匹配某一列并范围匹配某一列 只访问索引的查询，无须访问数据行 查询限制 如果不是最左列开始查询，则无法使用索引 不能跳过索引的列 如果某一列是范围查询右边的所有列无法使用索引优化查找 哈希索引 精确匹配所有索引列的查询才有效，存储引擎会根据所有的所有列计算一个哈希值。只有Memory显式支持哈希索引，并且是非唯一索引，如果哈希值相同，会以链表的形式存放多个数据记录在同一个哈希条目中。 查询限制 只包含哈希值和指针，不能避免读取数据行 不是按照顺序存储的，无法实现排序 不支持用于部分索引列的匹配查找，哈希值是通过所有索引列计算哈希值的 只支持等值比较查找 = ,IN(),&lt;&gt;,&lt;=&gt; 访问哈希索引的数据非常快，除非出现哈希冲突，存储引擎必须遍历所有的行指针 出现哈希冲突较多，索引维护的代价会很高 InooDB的自适应哈希索引 在B-Tree的基础上添加哈希索引。用户无法操纵，但是可以选择开启和关闭。 使用什么计算哈希值 CRC32， SHA1()，MD5()作为哈希函数产生的哈希值很长 自定义哈希函数 或者使用SHA1()，MD5()作为哈希函数结果的一部分来作为哈希值（性能低，实现简单） FNV64函数以插件方式使用，哈希值是64位的，冲突比CRC32少很多 空间数据索引（R-Tree） 从所有维度索引数据，可以使用任何维度来组合查询。 MySQL的GIS支持不完善很少使用 PostgreSQL的PostGIS比较好 全文索引 查找文本的关键词，类似搜索引擎的工作。 SQL优化 负向查询不能使用索引 1select name from user where id not in (1,3,4); 应该修改为: 1select name from user where id in (2,5,6); 前导模糊查询不能使用索引 1select name from user where name like &#x27;%zhangsan&#x27; 非前导则可以: 1select name from user where name like &#x27;zhangsan%&#x27; 建议可以考虑使用 Lucene 等全文索引工具来代替频繁的模糊查询。 数据区分不明显的不建议创建索引 如 user 表中的性别字段，可以明显区分的才建议创建索引，如身份证等字段。 字段的默认值不要为 null 这样会带来和预期不一致的查询结果。 在字段上进行计算不能命中索引 1select name from user where FROM_UNIXTIME(create_time) &lt; CURDATE(); 应该修改为: 1select name from user where create_time &lt; FROM_UNIXTIME(CURDATE()); 最左前缀问题 如果给 user 表中的 username pwd 字段创建了复合索引那么使用以下SQL 都是可以命中索引: 12345select username from user where username=&#x27;zhangsan&#x27; and pwd =&#x27;axsedf1sd&#x27;select username from user where pwd =&#x27;axsedf1sd&#x27; and username=&#x27;zhangsan&#x27;select username from user where username=&#x27;zhangsan&#x27; 但是使用 1select username from user where pwd =&#x27;axsedf1sd&#x27; 是不能命中索引的。 如果明确知道只有一条记录返回 1select name from user where username=&#x27;zhangsan&#x27; limit 1 可以提高效率，可以让数据库停止游标移动。 不要让数据库帮我们做强制类型转换 1select name from user where telno=18722222222 这样虽然可以查出数据，但是会导致全表扫描。需要修改为 1select name from user where telno=&#x27;18722222222&#x27; 如果需要进行 join 的字段两表的字段类型要相同 不然也不会命中索引","categories":[{"name":"数据库","slug":"数据库","permalink":"https://duanjiaojiao316.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"计算机网络基础知识","slug":"计算机网络基础知识","date":"2020-03-09T13:56:09.000Z","updated":"2021-04-20T07:44:33.824Z","comments":true,"path":"2020/03/09/计算机网络基础知识/","link":"","permalink":"https://duanjiaojiao316.github.io/2020/03/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"计算机网络 网络层 ICMP网际控制报文协议 ICMP报文是IP层数据报文的数据，加上IP头部组成IP报文。 种类 ICMP差错报告报文 终点不可达：当路由器或者主机不能交付数据报时，就向源点发送终点不可达报文。 时间超过：当路由器收到生存时间为0的数据报时，丢失数据报，向源点发送时间超过报文。当终点在预定时间段内不能收到数据报的全部内容，就会丢弃已收到的数据报，向源点发送时间超过报文。 参数问题：当路由器或者主机在收到数据报时发现首部的有些字段的值不正确时，丢弃该数据报，就会向源点发送参数问题报文。 改变路由（重定向）：路由器把改变路由报文发送给主机，让主机直到下次发送数据报更好的路由路径。 ICMP询问报文 回送请求和回答：主机或者路由器向一个特定的目的主机发送访问，收到此报文的主机必须给源主机或者路由器发送ICMP回送回答报文。这种询问报文用于测试目的站点是否可达。 时间戳请求和回答：请求某台主机或者路由器回答当前的时间和日期。可用于时钟同步和时间测量。 PING是ICMP的一个重要的应用，测试两台主机的连通性。 路由选择协议 内部网关协议RIP 一种分布式的基于距离向量的路由选择协议，路由表维护从自己到其他目的网络的距离（距离向量，跳数）。RIP允许一条路径最多只能包含15个路由器，距离为16时不可达，RIP只适用于小型互联网。 RIP不能在两个网络之间同时使用多条路径，RIP选择具有最少路由器的路径，哪怕存在一个具有较多路由器但是高速的 RIP协议特点： 仅与相邻的路由交换信息 交换信息为全部的路由表 按固定时间间隔交换路由信息 实现简单，开销小，好消息传的快，坏消息传的慢。 算法： 相邻路由器发来的RIP报文，对所有项目进行修改，把下一跳的路由都改成相邻路由器，距离都加1。 修改后的报文项目与将要更新的路由表进行对比： 原来的路由表中没有该目的网络，就加入该项目。 若下一跳的路由器是相邻路由器，则更新下一跳距离。 如果存在目标网络，但是下一跳路由不同，选择其中较小的。 如果三分钟后没有收到相邻路由表的更新信息，那么这个路由不可达，设置距离为16。 内部网关协议PSPF 使用迪杰斯特拉算法（Dijkstra）——最短路径优先 协议不收厂商控制——开发 分布式链路状态协议 OSPF特点： 向本自治系统的所有路由器发送信息——洪泛法，而RIP只向相邻的路由器发送信息。 发送信息是该路由与相邻路由的所有路由器的链路状态。链路状态是与哪些路由相邻以及该链路的度量（费用、距离、时延、带宽）。 只有链路状态发生变化路由器采用洪泛法发送此信息。 在OSPF中，没有路由器都知道全网的链路状态。 为了使OSPF用于更大的网络，将自治系统再划分为区域，划分区域，将洪泛法交换链路信息的范围局限于一个区域，减少整个网络的通信量。 外部网关协议BGP 配置BGP每一个自治系统都需要一个BGP发言人，为边界路由器发言人之间通过共享网络连接在一起。通过TCP发送，交换网络可达性信息。 传输层 IP层通信的两端是两台主机，运输层通信的两端是主机之间的进程。 运输层的复用与分用 复用是指发送方不同的应用程序都可以使用同一个运输层协议传送数据。 分用是指接收方的传输层剥去报文的首部后能够把这些数据正确交付到目的应用进程。 协议端口号 TCP/IP的运输层用16位端口号标记一个端口。端口号只具有本地意义。 服务器端使用的 熟知端口号（系统端口号）0-1023 应用程序 FTP TELNET SMTP DNS TFTP HTTP SNMP SNMP(trap) HTTPS 熟知端口号 21 23 25 53 69 80 161 162 443 登记端口号1024-49151 客户端使用的端口号49152-65535 用户数据报协议UDP 特点 无连接 尽最大努力交付 面向报文 发送方的UDP对应用层交下来的报文添加首部后就下交付IP层。对应用层下交下来的报文不合并不拆分。一次发送一个报文。 没有拥塞控制 首部开销小 支持一对一一对多多对一多对多的交互通信 由于UDP之间的通信要用到端口号，但是无连接的因此不需要使用套接字来建立连接。相比TCP就需要在两个套接字之间建立连接。 计算检验和 方法与IP检验相似，但是IP数据报的检验和只检验IP数据报的首部，UDP检验和把首部和数据部分一起检验。 步骤： 先把全零放入检验和字段 把伪首部和用户数据报看成许多16位的字串联用户数据报的数据不是偶数字节（也就是不是16位）不是则要填入全零。 二进制反码求和 求和结果写入检验和字段 UDP数据报发送。接收方二进制反码求这16位的和。结果为1无差错。 传输控制协议TCP 面向连接的传输层协议 每条连接只能连接两个端点 可靠交付 全双工通信 面向字节流 停止等待协议ARQ 每发送一个分组就会停止发送，等待对方的确认，在收到确认之后在发送下一个分组。发送方在一段时间后没有收到确认就会重传前面发送过的分组，超时重传。所以发送方都会暂时保存已发送分组的副本，只有在收到确认之后才会清楚副本。 发送方和接收方发送分组都需要进行编号。 确认丢失，接收方发送的确认分组丢失，发送方重传，接收方重复收到分组： 丢弃这个分组，不向上层交付 向发送方重新发送确认分组 确认迟到，接收方发送的确认迟到，发送方收到重复的确认，发送方丢弃确认，不做任何处理。 连续的ARQ协议 发送方维持发送窗口，发送方每发送一个分组，窗口就会向前移动一个分组的位置，接收方采用累计确认的方法，不必对接收的每个分组逐个发送确认，而是对按照次序到达的最后一个分组的发送确认。表明这个分组之前的所有分组全部到达。 累积确认的优点缺点： 容易实现，确认丢失也不必重传 不能向发送方反应接收方已经正确收到的所有分组的信息 TCP报文首部 **ACK **当ACK=1确认号字段才有效。 SYN 当SYN=1 ACK=0这是一个连接请求报文段，若对方同意建立连接，在响应的报文段SYN=1 ACK =1。 所以当SYN=1表明这是一个连接请求或者链接接受报文。 FIN 当FIN=1表明此报文段的发送方的数据发送完毕，并请求释放运输连接。 窗口 发送本报文段的一方的接收窗口。窗口值为了告诉发送方目前接收方允许发送的数据量。 计算机网络——DNS系统 DNS起源 由于要访问网络上的计算机，就需要直到其IP地址，但是IP地址是一段没有规律的数组，很难记忆，一旦一个计算机改变其IP地址就需要告知所有人。 为了方便记忆人们为计算机起名字，建立计算机名字到地址的一个映射关系。我们访问计算机的名字，剩下的名字到地址的转换过程则由计算机自动完成。 早期，名字到地址的转换过程十分简单。每台计算机保存一个hosts文件，里面列出所有计算机名字和对应的IP地址，然后定期从一个维护此文件的站点更新里面的记录。当我们访问某个计算机名字时，先在hosts文件找到对应的IP，然后就可以建立连接。 早期的ARPANET就是这样做的，但是随着网络规模的扩大，这种方法渐渐吃不消了。主要有以下三个原因： hosts文件变得非常大； 主机名字会冲突； 集中的维护站点会不堪重负（需要给几百万机器提供hosts文件，想想就可怕）。 为了解决上面的问题，1983年Paul Mockapetris提出了域名系统（ DNS, Domain Name System)，这是一种层次的、基于域的命名方案，并且用一个分布式数据库系统加以实现。当我们需要访问一个域名（其实就是前面说的计算机的名字）时，应用程序会向DNS服务器发起一个DNS请求，DNS服务器返回该域名对应的IP地址。通过下面三种手段解决了上面的问题： 用户计算机上并没有存储所有的名字到IP的映射，这样避免了hosts文件过于庞大（现在各操作系统中hosts文件默认都是空的）。 规定了域名的命名规则，保证主机名字不会重复。 DNS服务器不再是单一的一台机器，而是一个层次的、合理组织的服务器集群。 这样访问一个域名的过程可以简化为下图： DNS协议 那么如何具体实现这个所谓的域名系统呢，要知道管理一个超大型并且不断变化的域名到IP的映射集合可不是一个简单的事，况且还要去应付成千上万的DNS查询请求。人们最终想出了一套不错的协议，规定如何来实现这个系统，下面我们一起来看看吧。 首先我们需要制定一套命名规则，防止域名出现重复。DNS关于域名的规则和我们生活中的快递系统类似，使用层次的地址结构。快递系统中要给某人邮寄物品，地址可能是这样：中国、广东省、广州市、番禺区、中山西路12号 XXX。而一个域名看起来则是这样的groups.google.com（为什么不是com.google.groups？我猜可能和老外写地址的习惯有关）。 对于Internet来说，域名层次结构的顶级（相当于国际快递地址中的国家部分）由ICANN（互联网名称与数字地址分配机构）负责管理。目前，已经有超过250个顶级域名，每个顶级域名可以进一步划为一些子域（二级域名），这些子域可被再次划分（三级域名），依此类推。所有这些域名可以组织成一棵树，如下图所示: DNS设计之初是用来建立域名到IP地址的映射，理论上对于每一个域名我们只需要在域名服务器上保存一条记录即可。这里的记录一般叫作域名资源记录，它是一个五元组，可以用以下格式表示： 1Domain_name Time_to_live Class Type Value 其中： Domain_name：指出这条记录适用于哪个域名； Time_to_live：用来表明记录的生存周期，也就是说最多可以缓存该记录多长时间（后面会讲到缓存机制）； Class：一般总是IN； Type：记录的类型； Value：记录的值，如果是A记录，则value是一个IPv4地址。 我们看到域名资源记录有一个Type字段，用来表明记录的类型。这是为什么呢？因为对于一个域名来说，通常并非只记录其IP地址，还可能需要一些其他种类的记录，一些常见的记录类型如下： 我们知道不能只用一台域名服务器来响应所有的DNS查询，因为没有一台机器能够给全球的用户提供查询服务，计算能力、存储、带宽都不允许。只能合理组织一个域名服务器集群，使他们协同工作，共同提供域名解析服务。接下来首先要面对的一个问题是如何合理地将所有的域名资源记录存储到不同的域名服务器上。 前面说过域名的名字空间可以组织为一棵树，这里我们可以进一步将其划分为不重叠的区域（DNS zone），针对上图的域名空间，一种可能的域名划分如下图： 然后将每个区域与多个域名服务器（其中一个是master，其他slave服务器则用来提供数据备份、加快解析速度、保证服务可用性）关联起来，称这些域名服务器为该区域的权威域名服务器(Authoritative Name Servers )，它保存两类域名资源记录： 1：该区域内所有域名的域名资源记录。 2：父区域和子区域的域名服务器对应的域名资源记录（主要是NS记录）。 这样，所有的域名资源记录都保存在多个域名服务器中，并且所有的域名服务器也组成了一个层次的索引结构，便于我们后面进行域名解析。下面以一个简化的域名空间为例子，说明域名资源记录是如何保存在域名服务器中的，如下图: 图中域名空间划分为A, B, C, D, E, F, G七个DNS区域，每个DNS区域都有多个权威域名服务器，这些域名服务器里面保存了许多域名解析记录。对于上图的NDS区域E来说，它的权威域名服务器里面保存的记录如图中表格所示。 仔细观察上图你可能会发现区域A、B并没有父区域，他们之间并没有一条路径连在一起。这将导致一个很麻烦的问题，那就是区域A的权威域名服务器可能根本不知道区域B的存在。认识到这一点后，你可能会想出一个很自然的解决方案，就是在A中记录B域名服务器的地址，同时在B中记录A的，这样它们两个就联系起来了。但是考虑到我们有超过250个顶级域名，这样做并不是很恰当。 而我们使用的域名系统则采用了一种更加聪明的方法，那就是引入根域名服务器，**它保存了所有顶级区域的权威域名服务器记录。**现在通过根域名服务器，我们可以找到所有的顶级区域的权威域名服务器，然后就可以往下一级一级找下去了。下图为全球根域名服务器的分布图，可以在这里找到。 现在为止，我们的权威域名服务器和根域名服务器其实组成了一个树，树根为根域名服务器，下面每个节点都是一个区域的权威域名服务器，对于图a中各个DNS区域的权威域名服务器，它们组成了下面这棵树（实际中，一个权威域名服务器可能保存有多个DNS区域的记录，因此权威域名服务器之间的联系并不构成一棵树。这部分的详细内容可以参考RFC 1034: 4. NAME SERVERS。下面为了容易理解，将其简化为一棵树）： ​ 域名服务器树 域名解析 我们已经有了一个域名服务器集群，该集群合理地保存了域名空间和域名资源记录的对应关系。现在我们要做的就是发送一个DNS请求给域名服务器，然后坐等它返回正确的域名资源记录，这个过程叫作域名解析。 严格来说，域名解析的过程最早要追溯到建立网络连接。因为每当连接上网络之后，计算机会自动获得一个默认的DNS服务器，当然你也可以用自己信任的DNS服务器，比如8.8.8.8（DNS服务器也有信任不信任之分，是的，实践篇会讲到），我们把这个域名服务器也叫作本地域名服务器。接下来当我们需要知道一个域名对应的资源记录时，会向本地域名服务器发起请求，如果该域名恰好在本地域名服务器所辖属的域名区域（DNS zone）内，那么可以直接返回记录。 如果在本地域名服务器没有发现该域名的资源记录，就需要在整个域名空间搜索该域名。而整个域名空间的资源记录存储在一个分层的、树状联系的一系列域名服务器上，所以本地域名服务器首先要从根域名服务器开始往下搜索。这里有一个问题就是本地域名服务器如何找到根域名服务器在哪里呢？其实域名服务器启动的时候，就会加载一个配置文件，里面保存了根域名服务器的NS记录（要知道根域名服务器地址一般非常稳定，不会轻易改变，并且数量很少，所以这个配置文件会很小）。找到根域名服务器之后，就可以一级一级地往下查找啦。 仍然以我们的图a为例，现在假设区域E内的某个用户想访问math.sysu.edu.cn，那么请求的过程如下： ​ 域名解析过程 用语言简单描述如下： 1：用户：喂，本地域名服务器，告诉我math.sysu.edu.cn的地址； 2：本地域名服务器：哎呀，我不知道啊，不在我的辖区，容我去问问老大哥吧。root老大，能告诉我math.sysu.edu.cn的地址吗； 3：根域名服务器：忙着呢，你去问B（.cn）； 4：本地域名服务器：喂，B，告诉我math.sysu.edu.cn的地址； 5：B：你去问D（.edu.cn）； 6：本地域名服务器：喂，D，告诉我math.sysu.edu.cn的地址； 7：D：你去问F（sysu.edu.cn）； 8：本地域名服务器：喂，F，告诉我math.sysu.edu.cn的地址； 9：F：容老衲看看，哎呀，找到了，是X.X.X.X； 10：本地域名服务器：踏破铁鞋终于找到啦，喂用户，出来啊，我找到了，是X.X.X.X 缓存机制 现在整个域名系统已经可以为我们提供域名解析服务了，当我们输入域名，计算机发送DNS请求，然后DNS服务器返回给我们解析的结果，一切看起来很完美。然而是不是可以更完美呢？ 回顾一下平时浏览网站的情况，我们会发现两个比较有意思的结论： 1：80%的时间我们都在看那些20%的网站，这就是大名鼎鼎的80/20 Rule； 2：我们会在一个网站的不同网页之间跳转，也就是不断地访问同一个域名，类似程序访问的局部性原理。 这两条结论很容易让我们联想到缓存机制。如果我们将已经访问过的那些域名的解析结果缓存在自己的计算机上，那么下次访问的时候可以直接读取结果，不用再次重复DNS查询过程，给自己和域名服务器都节省了麻烦。 当然，这样做的一个前提是要缓存的解析结果不会频繁更改，也就是说我十分钟后解析一个域名的结果和现在解析的结果是一样的。对大多数域名来说，这都是一个不争的事实。但是难免有一些“善变”的域名，他们可能会频繁更改自己的解析结果。为了使缓存机制适应这两类情况，我们在域名资源记录里面添加一个Time_ti_live字段，表明这条记录最多可以缓存多久。对于那些“稳如泰山”的域名，给一个比较大的值，而那些“朝三暮四”的域名，则可以给定一个小的值。 我们既然可以在本机利用缓存，那么可不可以在域名服务器上也利用缓存机制呢，答案当然是可以的。因为对于域名服务器来说，上面的两条有意思的结论仍然有效。所以，域名服务器可以将那些访问过的域名资源记录缓存，用户再次发起请求时，可以直接返回缓存结果，不用去迭代或者递归解析。 域名注册、绑定 首先明确一点，每个人都可以去注册域名。大多数时候我们希望去注册一个顶级域名（比如selfboot.cn, google.com等），那些二级域名毕竟不够好记（比如github托管博客的域名：username.github.io）。有的顶级域名（比如.tk域名）提供免费的一年域名试用，不过绝大多时候还是要为自己的域名付费的（一般是按年付费，也不是很贵）。 要想去注册域名，首先得找到域名注册商，国内的比较著名的有DNSpod等，国外的有godaddy等。相信注册过域名的人都知道绝大多数我们能想到的自己喜欢的域名都已名花有主了，只剩那些不是那么惹人关注的域名供我们选择。所以，注册域名时，发现自己每想到一个域名都显示被人注册后，那太正常不过了，说明你的品味比较正常。 这里一点个人建议，选中一个域名后不要轻易去改了，因为换域名成本挺高的（我猜现在就算给淘宝一千万，它也不会换另成一个域名吧）。所以，最好不要去用免费的域名，因为指不定啥时候就不让你用了。你应该相信这么一个观点：天下没有免费的午餐。拓展一下就是，掏钱买服务，心里踏实。 接下来你可能会希望将自己的站点或者博客挂在自己选中的域名下，这其实很简单，只需要找到一个提供域名解析的服务商，然后填写相应的域名解析记录。大多时候，你注册域名的服务商都会免费提供域名解析服务。 现实中，大部分人可能会拥有个人博客，以前我们都是依赖一个博客平台（如CSDN），或者是买一台VPS托管自己的博客。不过自从Github推出了Blog服务，好多程序员都转而将博客托管在上面。Github Blog支持绑定个人域名，并提供了详细的绑定文档：Adding a CNAME file to your repository。假设你的博客已经可以通过 username.github.io 访问，接下来只需要用 CNAME 告诉Github你的博客绑定了哪个域名（比如说是selfboot.cn），然后在域名解析商那里添加解析记录即可，下图是我个人博客在DNSpod的解析记录： 现在当我们访问 selfboot.cn 时，DNSpod就会将请求解析到 Github 提供的 IP 地址上。之后 Github 上面的博客托管服务器在所有用户的 CNAME 记录中，找到本次请求的域名对应的博客项目地址，比如说是 xuelangZF.github.io，然后返回博客内容。 域名解析 我们都知道一个域名的解析过程中，可能会有多台域名服务器给我们帮助，那么我们怎么能看到这些背后的功臣呢？先介绍两个常用的关于DNS的命令。 dig(Domain Information Groper), 是 UNIX/BSD 系统自带的 DNS 诊断工具，使用十分灵活、方便。 查询 selfboot.cn 的A记录，并返回简短的结果： 用 dig 还可以查询某一 ip 对应的域名，如下： 这里返回的是pages.github.com，因为当你访问博客地址 selfboot.cn 时，其实是Github的pages 服务器（域名是：pages.github.com）在后台返回该博客内容的（根据 CNAME 确定返回哪个博客）。 nslookup 也是一个 DNS 诊断工具，几乎所有平台都自带该工具，使用也很简答，可以用 man 查询手册。 解析路径查询 接下来用 dig 命令查看从根域名到指定域名中间可能经过的所有域名服务器，使用 +trace 选项即可。 可以看到最开始是13台顶级域名服务器的NS记录（中间省去一些记录减少行数，方便观察更清楚），接下来是顶级域名 cn. 的权威域名服务器（省略一些输出），然后是 selfboot.cn 的 NS 记录，即 DNSpod 的两条 NS 记录，最后从 f1g1ns2.dnspod.net 找到 selfboot.cn 的 A 记录。 seveas 提供了一个可视化的路径查询工具：dnsgraph，可以在线绘制跟域名到指定域名的所有可能路径。 当然，实际查询过程中，大多时候我们在本地缓存或者本地域名服务器缓存就能直接找到需要的域名记录，不需要每次都向根域名服务器发起请求，然后重复迭代或者递归查询过程。 DNS缺陷 域名系统设计的很理想很美好，然而仍有一些小的瑕疵，可能会给我们带来些许困扰，首先，有些域名对注册人没有限制，而另外一些域名则对谁可以得到一个域名空间中名字有限制。比如pro域名是分配给合适的专业人员，但问题是谁才是专业的呢？显然医生、工程师是专业人员，但理发师、管道工呢？ 此外，域名也可以被倒卖。黄牛们会批量注册大量域名（据说com域名下几乎每一个普通词都被人尝试注册了域名），然后转身就以高价转卖给那些对该域名感兴趣的人，这就是所谓的域名抢注。所以，现在你想注册一个符合自己网站特点的域名是很难的。 这个问题其实还不算严重，更要命的是下面两个问题。 DNS劫持 我们知道一个域名服务器对其区域内的用户解析请求负责，但是并没有一个机制去监督它有没有真地负责。也就是说域名服务器的权力并没有被关在笼子里，所以它既可以认真地“为人民服务”，也可以指鹿为马。于是有些流氓的域名服务器故意更改一些域名的解析结果，将用户引向一个错误的目标地址。这就叫作 DNS 劫持，主要用来阻止用户访问某些特定的网站，或者是将用户引导到广告页面。 下面验证下我所用的域名服务器有没有干这种坏事，只需要一条简单的命令即可： 我的DNS服务器地址为10.8.4.4，他告诉我google.com的地址是120.196.0.5，我才不信呢。于是用whois 120.196.0.5一看，果真不是Google的地址。针对DNS劫持，我们可以简单地更换域名服务器，比较靠谱的一个是Google提供的8.8.8.8。下面用 8.8.8.8 来解析一下 www.google.com 就能看到正确的地址了。 DNS欺骗 DNS 劫持通过简单的切换域名服务器就可以绕过，不过一旦你遇上了 DNS 欺骗，就无法简单地绕过了。下面我们用不同的域名服务器来查看 fb 的 IP 地址，结果都返回了同一个地址，看起来好像是真的一样，不过也仅仅是看起来而已。 这个地址并不是 fb 的服务器地址（可以在 ViewDNS 查询所有域名真实的域名资源记录，ViewDNS是个很好玩的网站，里面有许多有意思的工具）。其实我Google了一下这个地址，竟然发现了一篇不错的译文，看来这个地址早在 2011 年就有了特殊的含义（英文原文是相关阅读第一个）。 DNS 欺骗简单来说就是用一个假的 DNS 应答来欺骗用户计算机，让其相信这个假的地址，并且抛弃真正的 DNS 应答。在一台主机发出 DNS 请求后，它就开始等待应答，如果此时有一个看起来正确（拥有和DNS请求一样的序列号）的应答包，它就会信以为真，并且丢弃稍晚一点到达的应答。 实施 DNS 欺骗的关键在于伪造一个有特定序列号的应答包，并且让其抢先一步到达发起请求的主机。这对于个人来说还有点难度，但是对于拥有骨干网节点的组织来说，实在是易如反掌，所以这么多网站都已沦陷。不过使用网上流传的那些 hosts文件，就可以在本机缓存许多网站的ip地址，进而可以和部分网站通信。但是通过hosts文件并不能完全 Cross the Great FireWall，因为人家还有很多其他手段。 反向DNS 反向DNS是已经知道IP的前提下，查询域名。反向DNS也是采用分层查询方式，对于一个IP地址(比如106.10.170.118)，依次查询in-addr.arpa节点(如果是IPv6，则为ip6.arpa节点)，106节点，10节点，170节点，并在该节点获得106.10.170.118对应的域名。 计算机网络——SSL协议 非对称加密 对称加密的原理相对比较直观，而非对称加密听起来就有些神奇。经过非对称加密产生的密文，就算知道加密的方法，也无法获知原文。实现了非对称加密的经典算法是RSA算法。它来自于数论与计算机计数的奇妙结合。我们从下面的情境中体验一下RSA算法的妙处。 我是潜伏在龙凤大酒楼的卧底。想让下面信息以加密的方式发到总部：A CHEF HIDE A BED，厨子藏起来了一张床！这是如此的重要，需要立即通知总部。千万重要的是，不能让反革命的厨子知道。 第一步是转码，也就是将英文转换成某个对应的数字。这个对应很容易建立，比如： 将上面的信息转码，获得下面的数字序列： 这串数字完全没有什么秘密可言。厨子发现了这串数字之后，很容易根据数字顺序，对应字母表猜出来。 为了和狡猾的厨子斗智斗勇，我们需要对这串数字进一步加密。使用总部发给我们的锁，两个数字：3和10。我们分为两步处理。第一步是求乘方。第一个数字是3，也就是说，总部指示我们，求上面数字串的3次方： 将这串数字发回总部。中途被厨子偷看到，但一时不能了解其中的意思。如果还是像刚才一样对应字母表的话，信息是：AGBEFBIDEAHED，这串字母完全不包含正常的单词。 信息到了总部。总部开始用神奇的钥匙来解读。这个钥匙是3。在这个简单的粒子里，钥匙不小心和之前锁中的一个数字相同。但这只是巧合。复杂的情况下很容易让锁和钥匙不同。解锁过程也是两步。第一步求钥匙次的乘方，即3次方。第二步求它们除以10（锁之一）的余数。 这正是我们发送的信息。对应字母表，总部可以立即知道原来的信息。就此，我们简单的体验了RSA算法的使用过程。鉴于这里篇幅有限，这里不再详细解释RSA算法的原理。 SSL协议 可以看到，非对称加密从安全性上要强过对称加密。但天下没有免费的午餐。非对称加密的运算成本同样也比较高。为了兼顾效率和安全，SSL协议同时使用了非对称和对称加密。它用对称加密算法来加密信息本身。但对于安全性比较脆弱的对称加密密钥，则采用非对称加密的方式来传输。 SSL协议分为客户端和服务器端。通信的核心步骤很简单： （1）双方利用明文通信的方式确立使用的加密算法。 （2）利用非对称算法通信，交换一个密钥。 （3）该密钥用于对称加密算法，加密接下来的通信正文。 可以看到，SSL协议的关键是用一个非常安全的方式来交换一个对称密钥。交换的过程会比上面的描述更加复杂一些。 （1）客户发起请求时，除了说明自己支持的非对称加密算法，还会附加一个客户端随机数(client random)。 （2）服务器回复请求时，会确定非对称加密算法和哈希函数，并附上公钥。此外，服务器端还会在此次通信中附加一个服务器端随机数(server random)。 （3）客户端会产生第三个随机数(Premaster secret)，然后利用服务器确定的非对称加密算法和公钥来加密这个随机数，再发送给服务器端。 （4）客户端用自己的私钥解密第三个随机数。 （5）这样，客户端和服务器端都知道了三个随机数。双方各自用商量好的哈希函数从三个随机数获得对称加密的密钥。 即使明文通信的时候，某些信息被窃听，但第三步的非对称加密通信部分可以保证窃听者无法完整的获得三个随机数。这样，窃听者还是不知道对称加密的密钥是什么。这样，对称加密的密钥就在一个安全的环境中获得了。为了进一步安全，服务器的公钥会包含在一个数字证书中发送给客户。这样，客户还可以通过数字证书来验证服务器的身份，以免服务器本身出现问题。 今年来使用越来越广泛的HTTPS协议就是在SSL/TLS协议的基础上进行通信。HTTP协议在通信过程中要经过多重路由，很容易被窃听。经过SSL协议加密的信息就算被窃听，也只能被通信目的地的人解读，从而保证了信息的安全。所以，如果所访问的网站没有使用HTTPS协议，那么在输入银行账号和密码之类的敏感信息时，就要三思而后行了。 一、SSL协议的握手过程 开始加密通信之前，客户端和服务器首先必须建立连接和交换参数，这个过程叫做握手（handshake）。 握手阶段分成五步。 第一步，爱丽丝给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。 第二步，鲍勃确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数（Server random）。 第三步，爱丽丝确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给鲍勃。 第四步，鲍勃使用自己的私钥，获取爱丽丝发来的随机数（即Premaster secret）。 第五步，爱丽丝和鲍勃根据约定的加密方法，使用前面的三个随机数，生成&quot;对话密钥&quot;（session key），用来加密接下来的整个对话过程。 二、私钥的作用 握手阶段有三点需要注意。 （1）生成对话密钥一共需要三个随机数。 （2）握手之后的对话使用&quot;对话密钥&quot;加密（对称加密），服务器的公钥和私钥只用于加密和解密&quot;对话密钥&quot;（非对称加密），无其他作用。 （3）服务器公钥放在服务器的数字证书之中。 从上面第二点可知，整个对话过程中（握手阶段和其后的对话），服务器的公钥和私钥只需要用到一次。这就是CloudFlare能够提供Keyless服务的根本原因。 某些客户（比如银行）想要使用外部CDN，加快自家网站的访问速度，但是出于安全考虑，不能把私钥交给CDN服务商。这时，完全可以把私钥留在自家服务器，只用来解密对话密钥，其他步骤都让CDN服务商去完成。 上图中，银行的服务器只参与第四步，后面的对话都不再会用到私钥了。 三、DH算法的握手阶段 整个握手阶段都不加密（也没法加密），都是明文的。因此，如果有人窃听通信，他可以知道双方选择的加密方法，以及三个随机数中的两个。整个通话的安全，只取决于第三个随机数（Premaster secret）能不能被破解。 虽然理论上，只要服务器的公钥足够长（比如2048位），那么Premaster secret可以保证不被破解。但是为了足够安全，我们可以考虑把握手阶段的算法从默认的RSA算法，改为 Diffie-Hellman算法（简称DH算法）。 采用DH算法后，Premaster secret不需要传递，双方只要交换各自的参数，就可以算出这个随机数。 上图中，第三步和第四步由传递Premaster secret变成了传递DH算法所需的参数，然后双方各自算出Premaster secret。这样就提高了安全性。 四、session的恢复 握手阶段用来建立SSL连接。如果出于某种原因，对话中断，就需要重新握手。 这时有两种方法可以恢复原来的session：一种叫做session ID，另一种叫做session ticket。 session ID的思想很简单，就是每一次对话都有一个编号（session ID）。如果对话中断，下次重连的时候，只要客户端给出这个编号，且服务器有这个编号的记录，双方就可以重新使用已有的&quot;对话密钥&quot;，而不必重新生成一把。 上图中，客户端给出session ID，服务器确认该编号存在，双方就不再进行握手阶段剩余的步骤，而直接用已有的对话密钥进行加密通信。 session ID是目前所有浏览器都支持的方法，但是它的缺点在于session ID往往只保留在一台服务器上。所以，如果客户端的请求发到另一台服务器，就无法恢复对话。session ticket就是为了解决这个问题而诞生的，目前只有Firefox和Chrome浏览器支持。 上图中，客户端不再发送session ID，而是发送一个服务器在上一次对话中发送过来的session ticket。这个session ticket是加密的，只有服务器才能解密，其中包括本次对话的主要信息，比如对话密钥和加密方法。当服务器收到session ticket以后，解密后就不必重新生成对话密钥了。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://duanjiaojiao316.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"mysql命令","slug":"mysql详细笔记","date":"2020-02-23T12:57:04.000Z","updated":"2021-04-20T07:44:33.815Z","comments":true,"path":"2020/02/23/mysql详细笔记/","link":"","permalink":"https://duanjiaojiao316.github.io/2020/02/23/mysql%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Windows服务 1234-- 启动服务net start mysql-- 创建Windows服务(注意等号与值之间有空格)sc create mysql binPath&#x3D; mysql_bin_path 连接与断开服务器 1234mysql -h 地址 -P 端口 -u 用户名 -p 密码SHOW PROCESSLIST -- 显示那些线程正在运行SHOW VARIABLES -- 显示系统变量信息 数据库操作 123456-- 查看当前数据库SELECT DATABASE();-- 显示当前时间、用户名、数据库版本SELECT now(),user(),version();-- 创建库CREATE DATABASE[IF NOT EXISTS] 数据库名 数据库选项","categories":[{"name":"数据库","slug":"数据库","permalink":"https://duanjiaojiao316.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql命令","slug":"mysql命令","permalink":"https://duanjiaojiao316.github.io/tags/mysql%E5%91%BD%E4%BB%A4/"}]},{"title":"Spring 框架两大核心机制（IoC、AOP）","slug":"Spring 框架两大核心机制（IoC、AOP）","date":"2020-02-23T12:57:04.000Z","updated":"2021-04-20T07:44:33.812Z","comments":true,"path":"2020/02/23/Spring 框架两大核心机制（IoC、AOP）/","link":"","permalink":"https://duanjiaojiao316.github.io/2020/02/23/Spring%20%E6%A1%86%E6%9E%B6%E4%B8%A4%E5%A4%A7%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6%EF%BC%88IoC%E3%80%81AOP%EF%BC%89/","excerpt":"","text":"Spring 框架两大核心机制（IoC、AOP） IoC（控制反转）/ DI（依赖注入） AOP（面向切面编程） Spring 是一个企业级开发框架，是软件设计层面的框架，优势在于可以将应用程序进行分层，开发者可以自主选择组件。 MVC：Struts2、Spring MVC ORMapping：Hibernate、MyBatis、Spring Data IoC 创建 Maven 工程，pom.xml 添加依赖 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.southwind&lt;/groupId&gt; &lt;artifactId&gt;aispringioc&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.11.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 创建实体类 Student 12345678910package com.southwind.entity;import lombok.Data;@Datapublic class Student &#123; private long id; private String name; private int age;&#125; 传统的开发方式，手动 new Student 12345Student student = new Student();student.setId(1L);student.setName(&quot;张三&quot;);student.setAge(22);System.out.println(student); 通过 IoC 创建对象，在配置文件中添加需要管理的对象，XML 格式的配置文件，文件名可以自定义。 12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.3.xsd&quot;&gt; &lt;bean id=&quot;student&quot; class=&quot;com.southwind.entity.Student&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;张三&quot;&gt;&lt;/property&gt; &lt;property name=&quot;age&quot; value=&quot;22&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 配置文件 通过配置 bean 标签来完成对象的管理。 id：对象名。 class：对象的模版类（所有交给 IoC 容器来管理的类必须有无参构造函数，因为 Spring 底层是通过反射机制来创建对象，调用的是无参构造） 对象的成员变量通过 property 标签完成赋值。 name：成员变量名。 value：成员变量值（基本数据类型，String 可以直接赋值，如果是其他引用类型，不能通过 value 赋值） ref：将 IoC 中的另外一个 bean 赋给当前的成员变量（DI） 1234567891011&lt;bean id=&quot;student&quot; class=&quot;com.southwind.entity.Student&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;张三&quot;&gt;&lt;/property&gt; &lt;property name=&quot;age&quot; value=&quot;22&quot;&gt;&lt;/property&gt; &lt;property name=&quot;address&quot; ref=&quot;address&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;address&quot; class=&quot;com.southwind.entity.Address&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;科技路&quot;&gt;&lt;/property&gt;&lt;/bean&gt; 从 IoC 中获取对象，通过 id 获取。 1234//加载配置文件ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;spring.xml&quot;);Student student = (Student) applicationContext.getBean(&quot;student&quot;);System.out.println(student IoC 底层原理 读取配置文件，解析 XML。 通过反射机制实例化配置文件中所配置所有的 bean。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package com.southwind.ioc;import org.dom4j.Document;import org.dom4j.DocumentException;import org.dom4j.Element;import org.dom4j.io.SAXReader;import java.lang.reflect.Constructor;import java.lang.reflect.Field;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;import java.util.HashMap;import java.util.Iterator;import java.util.Map;public class ClassPathXmlApplicationContext implements ApplicationContext &#123; private Map&lt;String,Object&gt; ioc = new HashMap&lt;String, Object&gt;(); public ClassPathXmlApplicationContext(String path)&#123; try &#123; SAXReader reader = new SAXReader(); Document document = reader.read(&quot;./src/main/resources/&quot;+path); Element root = document.getRootElement(); Iterator&lt;Element&gt; iterator = root.elementIterator(); while(iterator.hasNext())&#123; Element element = iterator.next(); String id = element.attributeValue(&quot;id&quot;); String className = element.attributeValue(&quot;class&quot;); //通过反射机制创建对象 Class clazz = Class.forName(className); //获取无参构造函数，创建目标对象 Constructor constructor = clazz.getConstructor(); Object object = constructor.newInstance(); //给目标对象赋值 Iterator&lt;Element&gt; beanIter = element.elementIterator(); while(beanIter.hasNext())&#123; Element property = beanIter.next(); String name = property.attributeValue(&quot;name&quot;); String valueStr = property.attributeValue(&quot;value&quot;); String ref = property.attributeValue(&quot;ref&quot;); if(ref == null)&#123; String methodName = &quot;set&quot;+name.substring(0,1).toUpperCase()+name.substring(1); Field field = clazz.getDeclaredField(name); Method method = clazz.getDeclaredMethod(methodName,field.getType()); //根据成员变量的数据类型将 value 进行转换 Object value = null; if(field.getType().getName() == &quot;long&quot;)&#123; value = Long.parseLong(valueStr); &#125; if(field.getType().getName() == &quot;java.lang.String&quot;)&#123; value = valueStr; &#125; if(field.getType().getName() == &quot;int&quot;)&#123; value = Integer.parseInt(valueStr); &#125; method.invoke(object,value); &#125; ioc.put(id,object); &#125; &#125; &#125; catch (DocumentException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e)&#123; e.printStackTrace(); &#125; catch (NoSuchMethodException e)&#123; e.printStackTrace(); &#125; catch (InstantiationException e)&#123; e.printStackTrace(); &#125; catch (IllegalAccessException e)&#123; e.printStackTrace(); &#125; catch (InvocationTargetException e)&#123; e.printStackTrace(); &#125; catch (NoSuchFieldException e)&#123; e.printStackTrace(); &#125; &#125; public Object getBean(String id) &#123; return ioc.get(id); &#125;&#125; 通过运行时类获取 bean 123ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;spring.xml&quot;);Student student = (Student) applicationContext.getBean(Student.class);System.out.println(student); 这种方式存在一个问题，配置文件中一个数据类型的对象只能有一个实例，否则会抛出异常，因为没有唯一的 bean。 通过有参构造创建 bean 在实体类中创建对应的有参构造函数。 配置文件 123456&lt;bean id=&quot;student3&quot; class=&quot;com.southwind.entity.Student&quot;&gt; &lt;constructor-arg name=&quot;id&quot; value=&quot;3&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;name&quot; value=&quot;小明&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;age&quot; value=&quot;18&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;address&quot; ref=&quot;address&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 123456&lt;bean id=&quot;student3&quot; class=&quot;com.southwind.entity.Student&quot;&gt; &lt;constructor-arg index=&quot;0&quot; value=&quot;3&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index=&quot;2&quot; value=&quot;18&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index=&quot;1&quot; value=&quot;小明&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index=&quot;3&quot; ref=&quot;address&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 给 bean 注入集合 123456789101112131415161718192021&lt;bean id=&quot;student&quot; class=&quot;com.southwind.entity.Student&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;2&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;李四&quot;&gt;&lt;/property&gt; &lt;property name=&quot;age&quot; value=&quot;33&quot;&gt;&lt;/property&gt; &lt;property name=&quot;addresses&quot;&gt; &lt;list&gt; &lt;ref bean=&quot;address&quot;&gt;&lt;/ref&gt; &lt;ref bean=&quot;address2&quot;&gt;&lt;/ref&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;address&quot; class=&quot;com.southwind.entity.Address&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;科技路&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;address2&quot; class=&quot;com.southwind.entity.Address&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;2&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;高新区&quot;&gt;&lt;/property&gt;&lt;/bean&gt; scope 作用域 Spring 管理的 bean 是根据 scope 来生成的，表示 bean 的作用域，共4种，默认值是 singleton。 singleton：单例，表示通过 IoC 容器获取的 bean 是唯一的。 prototype：原型，表示通过 IoC 容器获取的 bean 是不同的。 request：请求，表示在一次 HTTP 请求内有效。 session：回话，表示在一个用户会话内有效。 request 和 session 只适用于 Web 项目，大多数情况下，使用单例和原型较多。 prototype 模式当业务代码获取 IoC 容器中的 bean 时，Spring 才去调用无参构造创建对应的 bean。 singleton 模式无论业务代码是否获取 IoC 容器中的 bean，Spring 在加载 spring.xml 时就会创建 bean。 Spring 的继承 与 Java 的继承不同，Java 是类层面的继承，子类可以继承父类的内部结构信息；Spring 是对象层面的继承，子对象可以继承父对象的属性值。 12345678910111213141516171819202122232425&lt;bean id=&quot;student2&quot; class=&quot;com.southwind.entity.Student&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;张三&quot;&gt;&lt;/property&gt; &lt;property name=&quot;age&quot; value=&quot;22&quot;&gt;&lt;/property&gt; &lt;property name=&quot;addresses&quot;&gt; &lt;list&gt; &lt;ref bean=&quot;address&quot;&gt;&lt;/ref&gt; &lt;ref bean=&quot;address2&quot;&gt;&lt;/ref&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;address&quot; class=&quot;com.southwind.entity.Address&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;科技路&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;address2&quot; class=&quot;com.southwind.entity.Address&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;2&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;高新区&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;stu&quot; class=&quot;com.southwind.entity.Student&quot; parent=&quot;student2&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;李四&quot;&gt;&lt;/property&gt;&lt;/bean&gt; Spring 的继承关注点在于具体的对象，而不在于类，即不同的两个类的实例化对象可以完成继承，前提是子对象必须包含父对象的所有属性，同时可以在此基础上添加其他的属性。 Spring 的依赖 与继承类似，依赖也是描述 bean 和 bean 之间的一种关系，配置依赖之后，被依赖的 bean 一定先创建，再创建依赖的 bean，A 依赖于 B，先创建 B，再创建 A。通过依赖关系调整bean创建的先后顺序。 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd &quot;&gt; &lt;bean id=&quot;student&quot; class=&quot;com.southwind.entity.Student&quot; depends-on=&quot;user&quot;&gt;&lt;/bean&gt; &lt;bean id=&quot;user&quot; class=&quot;com.southwind.entity.User&quot;&gt;&lt;/bean&gt;&lt;/beans&gt; Spring 的 p 命名空间 p 命名空间是对 IoC / DI 的简化操作，使用 p 命名空间可以更加方便的完成 bean 的配置以及 bean 之间的依赖注入。 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.3.xsd&quot;&gt; &lt;bean id=&quot;student&quot; class=&quot;com.southwind.entity.Student&quot; p:id=&quot;1&quot; p:name=&quot;张三&quot; p:age=&quot;22&quot; p:address-ref=&quot;address&quot;&gt;&lt;/bean&gt; &lt;bean id=&quot;address&quot; class=&quot;com.southwind.entity.Address&quot; p:id=&quot;2&quot; p:name=&quot;科技路&quot;&gt;&lt;/bean&gt;&lt;/beans&gt; Spring 的工厂方法 IoC 通过工厂模式创建 bean 的方式有两种： 静态工厂方法 实例工厂方法 静态工厂方法 12345678910111213package com.southwind.entity;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Car &#123; private long id; private String name;&#125; 12345678910111213141516171819package com.southwind.factory;import com.southwind.entity.Car;import java.util.HashMap;import java.util.Map;public class StaticCarFactory &#123; private static Map&lt;Long, Car&gt; carMap; static&#123; carMap = new HashMap&lt;Long, Car&gt;(); carMap.put(1L,new Car(1L,&quot;宝马&quot;)); carMap.put(2L,new Car(2L,&quot;奔驰&quot;)); &#125; public static Car getCar(long id)&#123; return carMap.get(id); &#125;&#125; 1234&lt;!-- 配置静态工厂创建 Car --&gt;&lt;bean id=&quot;car&quot; class=&quot;com.southwind.factory.StaticCarFactory&quot; factory-method=&quot;getCar&quot;&gt; &lt;constructor-arg value=&quot;2&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 实例工厂方法 12345678910111213141516171819package com.southwind.factory;import com.southwind.entity.Car;import java.util.HashMap;import java.util.Map;public class InstanceCarFactory &#123; private Map&lt;Long, Car&gt; carMap; public InstanceCarFactory()&#123; carMap = new HashMap&lt;Long, Car&gt;(); carMap.put(1L,new Car(1L,&quot;宝马&quot;)); carMap.put(2L,new Car(2L,&quot;奔驰&quot;)); &#125; public Car getCar(long id)&#123; return carMap.get(id); &#125;&#125; 1234567&lt;!-- 配置实例工厂 bean --&gt;&lt;bean id=&quot;carFactory&quot; class=&quot;com.southwind.factory.InstanceCarFactory&quot;&gt;&lt;/bean&gt;&lt;!-- 赔偿实例工厂创建 Car --&gt;&lt;bean id=&quot;car2&quot; factory-bean=&quot;carFactory&quot; factory-method=&quot;getCar&quot;&gt; &lt;constructor-arg value=&quot;1&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; IoC 自动装载（Autowire） IoC 负责创建对象，DI 负责完成对象的依赖注入，通过配置 property 标签的 ref 属性来完成，同时 Spring 提供了另外一种更加简便的依赖注入方式：自动装载，不需要手动配置 property，IoC 容器会自动选择 bean 完成注入。 自动装载有两种方式： byName：通过属性名自动装载 byType：通过属性的数据类型自动装载 byName 123456789&lt;bean id=&quot;cars&quot; class=&quot;com.southwind.entity.Car&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;宝马&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;person&quot; class=&quot;com.southwind.entity.Person&quot; autowire=&quot;byName&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;11&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;张三&quot;&gt;&lt;/property&gt;&lt;/bean&gt; byType 123456789&lt;bean id=&quot;car&quot; class=&quot;com.southwind.entity.Car&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;2&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;奔驰&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;person&quot; class=&quot;com.southwind.entity.Person&quot; autowire=&quot;byType&quot;&gt; &lt;property name=&quot;id&quot; value=&quot;11&quot;&gt;&lt;/property&gt; &lt;property name=&quot;name&quot; value=&quot;张三&quot;&gt;&lt;/property&gt;&lt;/bean&gt; byType 需要注意，如果同时存在两个及以上的符合条件的 bean 时，自动装载会抛出异常。 AOP AOP：Aspect Oriented Programming 面向切面编程。 AOP 的优点： 降低模块之间的耦合度。 使系统更容易扩展。 更好的代码复用。 非业务代码更加集中，不分散，便于统一管理。 业务代码更加简洁存粹，不参杂其他代码的影响。 AOP 是对面向对象编程的一个补充，在运行时，动态地将代码切入到类的指定方法、指定位置上的编程思想就是面向切面编程。将不同方法的同一个位置抽象成一个切面对象，对该切面对象进行编程就是 AOP。 如何使用？ 创建 Maven 工程，pom.xml 添加 12345678910111213141516171819&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.11.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;5.0.11.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;5.0.11.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建一个计算器接口 Cal，定义4个方法。 12345678package com.southwind.utils;public interface Cal &#123; public int add(int num1,int num2); public int sub(int num1,int num2); public int mul(int num1,int num2); public int div(int num1,int num2);&#125; 创建接口的实现类 CalImpl。 123456789101112131415161718192021222324252627282930313233package com.southwind.utils.impl;import com.southwind.utils.Cal;public class CalImpl implements Cal &#123; public int add(int num1, int num2) &#123; System.out.println(&quot;add方法的参数是[&quot;+num1+&quot;,&quot;+num2+&quot;]&quot;); int result = num1+num2; System.out.println(&quot;add方法的结果是&quot;+result); return result; &#125; public int sub(int num1, int num2) &#123; System.out.println(&quot;sub方法的参数是[&quot;+num1+&quot;,&quot;+num2+&quot;]&quot;); int result = num1-num2; System.out.println(&quot;sub方法的结果是&quot;+result); return result; &#125; public int mul(int num1, int num2) &#123; System.out.println(&quot;mul方法的参数是[&quot;+num1+&quot;,&quot;+num2+&quot;]&quot;); int result = num1*num2; System.out.println(&quot;mul方法的结果是&quot;+result); return result; &#125; public int div(int num1, int num2) &#123; System.out.println(&quot;div方法的参数是[&quot;+num1+&quot;,&quot;+num2+&quot;]&quot;); int result = num1/num2; System.out.println(&quot;div方法的结果是&quot;+result); return result; &#125;&#125; 上述代码中，日志信息和业务逻辑的耦合性很高，不利于系统的维护，使用 AOP 可以进行优化，如何来实现 AOP？使用动态代理的方式来实现。 动态代理 给业务代码找一个代理，打印日志信息的工作交个代理来做，这样的话业务代码就只需要关注自身的业务即可。 123456789101112131415161718192021222324package com.southwind.utils;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.util.Arrays;public class MyInvocationHandler implements InvocationHandler &#123; //接收委托对象 private Object object = null; //返回代理对象 public Object bind(Object object)&#123; this.object = object; return Proxy.newProxyInstance(object.getClass().getClassLoader(),object.getClass().getInterfaces(),this); &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(method.getName()+&quot;方法的参数是：&quot;+ Arrays.toString(args)); Object result = method.invoke(this.object,args); System.out.println(method.getName()+&quot;的结果是&quot;+result); return result; &#125;&#125; 以上是通过动态代理实现 AOP 的过程，比较复杂，不好理解，Spring 框架对 AOP 进行了封装，使用 Spring 框架可以用面向对象的思想来实现 AOP。 Spring框架封装动态代理 Spring 框架中不需要创建 InvocationHandler，只需要创建一个切面对象，将所有的非业务代码在切面对象中完成即可，Spring 框架底层会自动根据切面类以及目标类生成一个代理对象。 LoggerAspect 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.southwind.aop;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.*;import org.springframework.stereotype.Component;import java.util.Arrays;@Aspect@Componentpublic class LoggerAspect &#123; @Before(value = &quot;execution(public int com.southwind.utils.impl.CalImpl.*(..))&quot;) public void before(JoinPoint joinPoint)&#123; //获取方法名 String name = joinPoint.getSignature().getName(); //获取参数 String args = Arrays.toString(joinPoint.getArgs()); System.out.println(name+&quot;方法的参数是：&quot;+ args); &#125; @After(value = &quot;execution(public int com.southwind.utils.impl.CalImpl.*(..))&quot;) public void after(JoinPoint joinPoint)&#123; //获取方法名 String name = joinPoint.getSignature().getName(); System.out.println(name+&quot;方法执行完毕&quot;); &#125; @AfterReturning(value = &quot;execution(public int com.southwind.utils.impl.CalImpl.*(..))&quot;,returning = &quot;result&quot;) public void afterReturning(JoinPoint joinPoint,Object result)&#123; //获取方法名 String name = joinPoint.getSignature().getName(); System.out.println(name+&quot;方法的结果是&quot;+result); &#125; @AfterThrowing(value = &quot;execution(public int com.southwind.utils.impl.CalImpl.*(..))&quot;,throwing = &quot;exception&quot;) public void afterThrowing(JoinPoint joinPoint,Exception exception)&#123; //获取方法名 String name = joinPoint.getSignature().getName(); System.out.println(name+&quot;方法抛出异常：&quot;+exception); &#125;&#125; LoggerAspect 类定义处添加的两个注解： @Aspect：表示该类是切面类。 @Component：将该类的对象注入到 IoC 容器。 具体方法处添加的注解： @Before：表示方法执行的具体位置和时机。 CalImpl 也需要添加 @Component，交给 IoC 容器来管理。 123456789101112131415161718192021222324252627package com.southwind.utils.impl;import com.southwind.utils.Cal;import org.springframework.stereotype.Component;@Componentpublic class CalImpl implements Cal &#123; public int add(int num1, int num2) &#123; int result = num1+num2; return result; &#125; public int sub(int num1, int num2) &#123; int result = num1-num2; return result; &#125; public int mul(int num1, int num2) &#123; int result = num1*num2; return result; &#125; public int div(int num1, int num2) &#123; int result = num1/num2; return result; &#125;&#125; spring.xml 中配置 AOP。 123456789101112131415161718&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.3.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.3.xsd&quot;&gt; &lt;!-- 自动扫描 --&gt; &lt;context:component-scan base-package=&quot;com.southwind&quot;&gt;&lt;/context:component-scan&gt; &lt;!-- 是Aspect注解生效，为目标类自动生成代理对象 --&gt; &lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;&lt;/beans&gt; context:component-scan 将 com.southwind 包中的所有类进行扫描，如果该类同时添加了 @Component，则将该类扫描到 IoC 容器中，即 IoC 管理它的对象。 aop:aspectj-autoproxy 让 Spring 框架结合切面类和目标类自动生成动态代理对象。 切面：横切关注点被模块化的抽象对象。 通知：切面对象完成的工作。 目标：被通知的对象，即被横切的对象。 代理：切面、通知、目标混合之后的对象。 连接点：通知要插入业务代码的具体位置。 切点：AOP 通过切点定位到连接点。","categories":[{"name":"后端","slug":"后端","permalink":"https://duanjiaojiao316.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://duanjiaojiao316.github.io/tags/Spring/"}]},{"title":"阅读redis设计与实现笔记","slug":"redis设计与实现笔记","date":"2020-02-23T12:57:04.000Z","updated":"2021-04-20T07:44:33.816Z","comments":true,"path":"2020/02/23/redis设计与实现笔记/","link":"","permalink":"https://duanjiaojiao316.github.io/2020/02/23/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"redis设计与实现笔记 第一部分 数据结构与对象 1.简单动态字符串 2.链表 3.字典 4.跳跃表 5.整数集合 6.压缩列表 7.对象 第二部分 单机数据库的实现 9.数据库 10.RDB持久化 11.AOF持久化 12.事件 13.客户端 14.服务器端 第三部分 多机数据库的实现 15.复制 16.Sential 17.集群 第四部分 独立功能的实现 18.发布与订阅 19.事务 一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。 事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。 Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。 为什么Redis不支持回滚 Redis命令在事务中可能会执行失败，但是Redis事务不会回滚，而是继续会执行余下的命令。如果您有一个关系型数据库的知识，这对您来说可能会感到奇怪，因为关系型数据在这种情况下都是会回滚的。 Redis这样做，主要是因为:只有当发生语法错误(这个问题在命令队列时无法检测到)了，Redis命令才会执行失败, 或对keys赋予了一个类型错误的数据：这意味着这些都是程序性错误，这类错误在开发的过程中就能够发现并解决掉，几乎不会出现在生产环境。由于不需要回滚，这使得Redis内部更加简单，而且运行速度更快。 20.lua脚本 21.排序 22.二进制数组 SETBIT为二进制数组指定偏移上的二进制位设置值 GETBIT获取二进制数组中指定偏移的二进制位的值 BITCOUNT计算二进制数组中以1为值的二进制位有多少个 BITOP可以对多个二进制数组进行按位与、按位或、按位异或、取反等操作。 字符串对象表示位数组，因为字符串对象使用SDS数据结构是二进制安全的，可以直接使用SDS数据结构来保存维数组。 SDS数据结构中buf数组中的顺序和平时书写顺序相反。 23.慢查询日志 记录执行时间超过给定时长的命令请求，用户通过慢日志查询的日志来监视和优化查询速度。 slowlog-log-slower-than 指定执行时间超过多少微妙的命令请求会被记录在日志之中。设置为0，所有的请求都会记录在日志中。 slowlog-log-max-len指定服务器最多可以保存多少命令请求。如果设置为5，服务器最多只能存储5个命令请求，以先进先出的方式保存，如果指令数量已经是slowlog-log-max-len，删除最旧的命令请求添加新的命令请求。 SLOWLOG GET命令查看服务器存储的慢查询日志。 1234567typedef struct slowlogEntry&#123; long long id;//唯一标识符 time_t time;//命令执行时的时间，Unix时间戳 long long duration;//执行命令消耗的时间 robj **argv;//命令与命令参数 int argc;//命令与命令参数的个数&#125; SLOWLOG_RESET清除慢查询日志中的所有日志。 添加新的日志 检查是否超过slowlog-log-slower-than ，如果查过创建一个新的日志添加在slowlog链表的表头。 判断链表的长度是否查过slowlog-log-max-len，如果查过就从链表的表尾删除一个。 24.监视器 通过MONITOR 命令客户端将自己变为一个监视器，实时接收打印服务器端处理命令请求的信息。当一个客户端向服务器发送一个请求，服务器除了处理命令请求还会将所有的信息发送给所有的监视器。 list *monitor 记录打开REDIS_MONITOR标志的客户端，也就是将自己变成监视器的客户端。 服务器端调用replicationFeedMonitors该函数来实现发送信息给所有监视器。 第五部分 面试题 1.Redis 具体有 6 种内存淘汰策略： 内存淘汰策略 策略 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选更早过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 noeviction 当内存不足以容纳新写入数据时，新写入操作会报错 redis 过期策略 redis 过期策略是：定期删除+惰性删除。 所谓定期删除，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。 假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的灾难。实际上 redis 是每隔 100ms 随机抽取一些 key 来检查和删除的。 但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。 获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。 但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？ 答案是：走内存淘汰机制。 2.项目中缓存是如何使用的？ 这个，需要结合自己项目的业务来。 为什么要用缓存？ 用缓存，主要有两个用途：高性能、高并发。 高性能 假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个结果，耗时 600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？ 缓存啊，折腾 600ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走 mysql 折腾 600ms 了，直接从缓存里，通过一个 key 查出来一个 value，2ms 搞定。性能提升 300 倍。 就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。 高并发 mysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 2000QPS 也开始容易报警了。 所以要是你有个系统，高峰期一秒钟过来的请求有 1万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 key-value 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。 缓存是走内存的，内存天然就支撑高并发。 3.如何保证缓存与数据库的双写一致性？ 一般来说，如果允许缓存和数据库偶尔有不一致的情况（要求不严格的情况下）最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。 串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。 Cache Aside Pattern 最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。 更新的时候，先更新数据库，然后再删除缓存。 为什么是删除缓存，而不是更新缓存？ 缓存的数据不是直接从数据库取出，而是经过复杂的计算 更新缓存的代价（频繁的数据库修改，频繁的缓存更新，但是却很少访问）只有用到的时候再重新计算放在缓存。 原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。 比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。 另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，这个缓存到底会不会被频繁访问到？ 举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有大量的冷数据。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。用到缓存才去算缓存。 其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都把里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。 不一致问题解决方法 1.先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。 解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。 2.数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了… 在高并发下缓存出现这个问题： 更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个 jvm 内部队列中。 一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。 了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？ 缓存雪崩 对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。 事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。 用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 redis。如果 ehcache 和 redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 redis 中。 限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？走降级！可以返回一些默认的值，或者友情提示，或者空白的值。 好处： 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。 只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。 只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来一次。 缓存穿透 对于系统A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。 黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。 举个例子：数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。 解决方式： 每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 UNKNOWN。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据 缓存击穿 缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。 解决方式： 可以将热点数据设置为永远不过期； 基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。 4.redis 和 memcached 有啥区别？ redis 支持复杂的数据结构 redis 相比 memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， redis 会是不错的选择。 redis 原生支持集群模式 在 redis3.x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。 性能对比 由于 redis 只使用单核，而 memcached 可以使用多核，所以平均每一个核上 redis 在存储小数据时比 memcached 性能更高。而在 100k 以上的数据中，memcached 性能要高于 redis。虽然 redis 最近也在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。 5.redis 都有哪些数据类型？分别在哪些场景下使用比较合适？ 除非是面试官感觉看你简历，是工作 3 年以内的比较初级的同学，可能对技术没有很深入的研究，面试官才会问这类问题。否则，在宝贵的面试时间里，面试官实在不想多问。 其实问这个问题，主要有两个原因： 看看你到底有没有全面的了解 redis 有哪些功能，一般怎么来用，啥场景用什么，就怕你别就会最简单的 KV 操作； 看看你在实际项目里都怎么玩儿过 redis。 要是你回答的不好，没说出几种数据类型，也没说什么场景，你完了，面试官对你印象肯定不好，觉得你平时就是做个简单的 set 和 get。 面试题剖析 redis 主要有以下几种数据类型： string hash list set sorted set string 这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。 1set college szu hash 这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 redis 里，然后每次读写缓存的时候，可以就操作 hash 里的某个字段。 123456789hset person name bingohset person age 20hset person id 1hget person nameperson &#x3D; &#123; &quot;name&quot;: &quot;bingo&quot;, &quot;age&quot;: 20, &quot;id&quot;: 1&#125; list list 是有序列表 比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。 比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。 12# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。lrange mylist 0 -1 比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。 123456lpush mylist 1lpush mylist 2lpush mylist 3 4 5# 1rpop mylist set set 是无序集合，自动去重。 直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 redis 进行全局的 set 去重。 可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？ 把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。 1234567891011121314151617181920212223242526272829303132#-------操作一个set-------# 添加元素sadd mySet 1# 查看全部元素smembers mySet# 判断是否包含某个值sismember mySet 3# 删除某个&#x2F;些元素srem mySet 1srem mySet 2 4# 查看元素个数scard mySet# 随机删除一个元素spop mySet#-------操作多个set-------# 将一个set的元素移动到另外一个setsmove yourSet mySet 2# 求两set的交集sinter yourSet mySet# 求两set的并集sunion yourSet mySet# 求在yourSet中而不在mySet中的元素sdiff yourSet mySet sorted set sorted set 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。 12345678910zadd board 85 zhangsanzadd board 72 lisizadd board 96 wangwuzadd board 63 zhaoliu# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）zrevrange board 0 3# 获取某用户的排名zrank board zhaoliu","categories":[{"name":"后端","slug":"后端","permalink":"https://duanjiaojiao316.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://duanjiaojiao316.github.io/tags/redis/"},{"name":"阅读笔记","slug":"阅读笔记","permalink":"https://duanjiaojiao316.github.io/tags/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}]},{"title":"mybatis基础","slug":"mybatis基础","date":"2020-02-21T11:45:55.000Z","updated":"2021-04-20T07:44:33.815Z","comments":true,"path":"2020/02/21/mybatis基础/","link":"","permalink":"https://duanjiaojiao316.github.io/2020/02/21/mybatis%E5%9F%BA%E7%A1%80/","excerpt":"","text":"mybatis基础 ORM 对象关系映射（Object Relational Mapping，简称ORM）是通过使用描述对象和数据库之间映射的元数据，面向对象语言程序中的对象自动持久化到关系数据库中。本质上就是将数据从一种形式转换到另外一种形式。 对象指的是变相对象 关系是指关系型数据库 Java到MySQL的映射，开发者可以以面向对象的思想来管理数据库 MyBatis的优点 对JDBC的封装，与JDBC相比减少了一定的代码量。 MyBatis是最简单的持久化框架，小巧简单易学。 MyBatis相对灵活，不会对应用程序或者数据库的现有设计强加任何影响。SQL语句写在xml文件中，从程序中彻底的分离，降低耦合度，便于统一管理，提高可重用性。 提供xml标签，支持动态sql语句编写 提供映射标签，支持对象与数据库的ORM字段关系映射 MyBatis的缺点 每一个sql都需要开发者编写，不像其他hibernate可以自动生成一些。sql语句的编写工作量大，尤其是字段多，关联表多时，对开发人员编写sql语句的功底有一定的要求。 sql语句依赖于数据库，导致数据库的移植性差，不能随意更改数据库。更换数据库就需要修改sql语句（mysql更换为Oracle）。 MyBatis的开发方式 1、使用原生接口 2、Mapper代理实现自定义接口","categories":[{"name":"后端","slug":"后端","permalink":"https://duanjiaojiao316.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://duanjiaojiao316.github.io/tags/mybatis/"}]},{"title":"Java虚拟机","slug":"JVM虚拟机","date":"2020-02-21T11:45:55.000Z","updated":"2021-04-20T07:44:33.811Z","comments":true,"path":"2020/02/21/JVM虚拟机/","link":"","permalink":"https://duanjiaojiao316.github.io/2020/02/21/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA/","excerpt":"","text":"Java虚拟机 第一部分 JVM基础 第一章 Java内存区域与内存溢出异常 运行时数据区域 1.程序计数器(线程私有) 当前线程执行的字节码的行号指示器。 Java虚拟机的多线程通过线程轮流切换并分配处理器执行时间的方式来实现，一个处理器或者多核处理器的一个内核只会执行一条线程，每条线程需要一个独立的程序计数器 如果线程在执行一个普通的Java方法，计数器记录正在执行的虚拟机字节码指令的地址； 如果线程正在执行一个Native方法，计数器的值为空； 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 2.Java虚拟机栈（线程私有） 虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时会创建一个栈帧用于存储局部变量表，操作数栈，动态链接、方法出口等信息。每个方法的执行过程，就对应一个栈帧在虚拟机栈中的入栈和出栈。 1）局部变量表 基本数据类型（boolean、byte、char、short、int、long、double） 对象引用（reference类型）对象本身、对象起始地址的引用指针、指向一个对象的句柄、其他与此对象相关的位置 returnAddress类型 指向一条字节码指令的地址 2）两种异常状态 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128&#96;&#96;&#96;OutOfMemoryError&#96;&#96;&#96;异常：虚拟机栈可以动态扩展，如果扩展的时无法申请到足够的内存#### 3.本地方法栈作用与Java虚拟机栈相似：Java虚拟机栈为Java方法服务，**抛出异常同虚拟机栈**。被动方法栈为Native方法服务#### 4.Java堆被所有的线程共享的一块内存区域，算是虚拟机所管理的内存中最大的一块，带区域主要存储对象实例，是主要垃圾收集器管理的区域。如果堆中没有内存完成实例分配，就会抛出OutOfMemoryError异常。#### 5.方法区各个线程共享区域，用于存储已被虚拟机加载的类信息、常量、静态常量、即时编译器编译后的代码等数据。#### 6.运行时常量池运行时常量池方法区的一部分1. Class文件存放类的版本、字段、方法、接口等描述信息外，还有常量池，常量池存放编译器生成的各种字面量和符号引用，这部分内容在类加载后进入方法区的**运行时常量池**存放。2. Java虚拟机对Class文件的每一部分的格式要求都有严格的规定。- 运行常量池Java虚拟机规范没有任何细节的要求。- 运行常量池中保存Class文件中描述的符号引用，翻译出来的直接引用也会存储在运行时常量池。- 运行时常量池具有动态性，不要求常量一定要在编译器产生，并非置入Class文件中常量池的内容才能进入方法区运行时常量区，运行期间也可以将常量放在运行常量池中##### **程序的执行方式有**：1. 静态编译执行：事前（编译时）编译，编译成机器码，直接由CPU执行2. 动态编译执行：运行时编译，JIT编译 动态编译通常指运行时将所有代码都编译 JIT编译将部分代码进行编译（热点代码）3. 动态解释执行：JVM有解析器，按照字节码指令逐行解析逐行执行，每次执行都需要解析。JIT编译比解释器快，说的是执行编译后的代码比解释器解释执行要快，而不是编译这个动作比解释快。对于只执行一次的代码而言，解释执行可能比编译执行要快。### &#96;&#96;&#96;HotSpot&#96;&#96;&#96;虚拟机对象#### 对象创建1. 遇到new现在常量池定位这个类的符号引用，没有进行类加载过程。2. 对象分配内存 1. 指针碰撞 java堆中内存绝对规整，所有用过的内存放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点指示器。&lt;font color&#x3D;&quot;red&quot;&gt;分配内存就是把指针向空闲部分挪动一段与对象大小相同的距离&lt;&#x2F;font&gt;。 2. 空闲列表 Java堆中内存不规整，虚拟机**维护一个列表**记录可以内存，分配之时从列表中查找足够大的内存即可。 多线程下对象内存分配 1. 对分配内存空间动作进行同步处理，采用CAS配上失败重方式保证更新操作的原子性。 2. 把内存分配动作按照线程划分为不同的空间之上运行，每个线程预先分得一块内存，本地线程分配缓冲（TLAB).那个线程的TLAB用完，分配新的TLAB才进行同步锁定。3. 对象内存布局 3个区域：对象头，实际数据，对齐填充 &lt;font color&#x3D;&quot;yellow&quot;&gt;hashcode，GC分代年龄，等等&lt;&#x2F;font&gt; &lt;font color&#x3D;&quot;red&quot;&gt;相同宽度的字段分配在一起，短的字段可以分配到之前字段的空缺位置，子类中的变量也可以分配在父类的字段部分&lt;&#x2F;font&gt; &lt;font color&#x3D;&quot;blue&quot;&gt;确保对象起始地址为8字节的整数倍。&lt;&#x2F;font&gt;4. 对象访问定位 1.通过句柄方式访问， 在Java堆中分出一块内存进行存储句柄池，这样的话，在栈中存储的是句柄的地址 [![img](https:&#x2F;&#x2F;images2017.cnblogs.com&#x2F;blog&#x2F;917948&#x2F;201709&#x2F;917948-20170912201713938-1421262172.png)](https:&#x2F;&#x2F;images2017.cnblogs.com&#x2F;blog&#x2F;917948&#x2F;201709&#x2F;917948-20170912201713938-1421262172.png) 优点： 当对象移动的时候（垃圾回收的时候移动很普遍），这样值需要改变句柄中的指针，但是栈中的指针不需要变化，因为栈中存储的是句柄的地址 缺点： 需要进行二次定位，寻找两次指针，开销相对于更大一些 2.直接指针访问方式 Java栈直接与对象进行访问，在Java堆中对象帆布中必须考虑存储访问类型的数据的相关信息，因为没有了句柄了 [![img](https:&#x2F;&#x2F;images2017.cnblogs.com&#x2F;blog&#x2F;917948&#x2F;201709&#x2F;917948-20170912202343719-636641418.png)](https:&#x2F;&#x2F;images2017.cnblogs.com&#x2F;blog&#x2F;917948&#x2F;201709&#x2F;917948-20170912202343719-636641418.png) 优点： 速度快，不需要和句柄一样指针定位的开销### 第二章垃圾收集器与内存分配策略#### 哪些区域的内存是垃圾收集器关注的？Java 内存中程序计数器，虚拟机栈和本地方法栈3个区域都是线程私有的，其中内存都会随着方法结束，线程结束自动回收。而堆内存和方法区的内存分配回收时垃圾收集器关注的部分。#### 对象死亡判断##### 1.引用计数算法对象添加一个计数器，每一次引用它就在计数器加一，每次引用失效，就在计数器减一。计数器为0的对象不能被使用，是垃圾回收的对象。缺点：很难解决对象之间相互引用问题&#96;&#96;&#96;javapublic class Test&#123; public Object instance &#x3D; null; public static void testGC()&#123; Test a &#x3D; new Test(); Test b &#x3D; new Test(); a.instance &#x3D; b; b.instance &#x3D; a; a &#x3D; null; b &#x3D; null; System.gc(); &#125;&#125; 2.可直达分析算法 通过一系列的GC Roots 的对象作为起始点，从这些结点开始向下搜索，搜索走过的路径成为引用链，当一个对象到GC Roots没有任何引用链，也就是从GC Roots到这个对象不可达，证明对象不可用。不可用对象将是可回收对象。 主流程序语言都是使用可直达算法作为判定对象是否存活的。 Java语言中可作为GC Roots的对象包括 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（即一般说的Native方法）引用的对象 引用 强引用 代码之中普遍存在类似 Object a = new Object();的引用，只要强引用还存在，垃圾收集器就不会回收被引用的对象 软引用 描述一些有用但是并非必须的对象，对于软引用对象，在系统发生内存溢出异常之前，把软引用对象列入回收范围之内进行第二次回收。如果第二次回收之后还是没有足够的内存才会抛出内存溢出的异常。 弱引用 描述非必要对象，强度比软引用弱，被弱引用引用的对象只能存活到下一次垃圾回收之前。当垃圾收集器工作时，无论内存是否足够，都会回收只被弱引用引用的对象。 虚引用 幽灵引用或者幻影引用，最弱的引用。该引用的存在不会影响垃圾回收，也无法通过虚引用来获取对象实例，唯一目的：能在垃圾回收时收到一个系统通知。 jdk中直接内存的回收就用到虚引用，由于jvm自动内存管理的范围是堆内存，而直接内存是在堆内存之外（其实是内存映射文件，自行去理解虚拟内存空间的相关概念），所以直接内存的分配和回收都是有Unsafe类去操作，java在申请一块直接内存之后，会在堆内存分配一个对象保存这个堆外内存的引用，这个对象被垃圾收集器管理，一旦这个对象被回收，相应的用户线程会收到通知并对直接内存进行清理工作。 finalize()方法 如果对象在可直达分析后发现没有与GC Roots相连接的引用链，它会进行第一次标记，进行进一步的筛选。 进一步的筛选条件是对象是否有必要执行finalize()方法，对象没有覆盖该方法或者该方法已经被虚拟机调用过，这两种情况都是没有必要执行。 如果这个对象有必要执行finalize()方法，这个对象就会放置在一个F-Queue队列中，稍后虚拟机建立Finalizer线程去执行。但是不等待它结束。 finalize方法是对象逃脱死亡的最后机会，只要在finalize中重新与引用链上任何对象建立关联，这个对象就会免死亡。没有逃脱，该对象就被回收了。 注意：finalize方法在面临第二次回收的时候不会在执行。 垃圾收集算法 1.标记清除算法 标记所有需要回收的对象，标记完成后统一回收被标记对象。 不足： 效率问题，标记和清除过程的效率都不高 空间问题，标记清除后产生大量不连续内存碎片，空间碎片太多导致分配较大对象时找不到足够的连续空间而不得不提前出发再一次垃圾收集。 2.复制算法 将内存划分为大小相同的两块，每次只使用一块，一块用完，就将存活的对象复制在另一块，并把原来的块的内存清空，对整个半区进行垃圾回收。 缺点：将内存区域缩小为原来的一半。 优化不按照1:1的比例划分而是划分为Eden和两个Survivor空间。每次使用Eden和其中一个Survivor，将存活的对象复制到两一个Survivor清理之前用过的Survivor和Eden空间。默认Eden空间和Survivor比例是8：1，由于新生代垃圾回收有98%对象需要回收。当回收的对象大于10%的时候借助其他内存如老年代。 3.标记整理算法 复制算法在存活率较高的情况下，进行较多的复制操作，效率降低。 针对老年代对象存活率较高，提出标记整理算法。 标记整理算法的标记过程与标记清除相同，清除过程将对象向一端移动然后清除边界以外的内存。 4.分代收集算法 把内存分成新生代和老年代，根据各个年代的特点采用适当的收集算法 HotSpot算法实现 1.枚举根结点 由于GC Roots的结点主要在全局性引用与执行上下文（栈帧中的本地变量表）中，光方法区就有数百兆，逐个检查这里的引用会消耗大量时间。 可达性分析对于执行时间的敏感性还体现在GC停顿上。分析性工作必须在一个确保一致的快照中进行。不可以出现对象引用关系的改变。需要停止Java执行线程（Stop The World） 主流Java使用准确式GC，在执行系统停顿下来，不需要一个不漏的检查所有执行上下文和全局的引用位置，虚拟机有办法知道哪些地方存放对象引用。在HotSpot的实现中，用OopMap数据结构达到这个目的，在类加载完成的时候，HotSpot就把对象内什么偏移上什么类型的数据计算出来，在JIT编译的过程中，会在特定的位置记录栈和寄存器中哪些地方是引用。 2.安全点 可能导致引用关系变化或者说OopMap的内容变化的指令很多，如果为每条指令都生成对应的OopMap，会消耗大量的额外空间。 HotSpot没有为每条可能改变引用关系的指令生成OopMap，而是在特定的位置记录，这些位置称为安全点。 到达安全点后，执行系统停顿开始GC，只有到达安全点之后才能停止。 在方法调用，循环跳转，异常跳转等功能指令下会产生Safepoint。 如何让所有的线程都跑到最近的安全点并停顿下来？ 抢占式中断 不需要线程主动配合，GC发生后所有线程中断，如果有的线程中断的地方不在安全点，就恢复线程让它执行到安全点。（几乎没有虚拟机使用抢占式中断） 主动式中断 当GC需要中断线程时，不直接对线程操作，而是设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真，就自己中断线挂起，轮询标志的地方和安全点重合，再加上创建对象分配内存的地方。 3.安全区域 程序不执行，在下次sleep和blocked状态下，这些线程无法响应JVM中断将线程执行到安全点的地方挂起。 安全区域是指在一段代码片段中引用关系不会发生变化。在线程执行到安全区域，就不用管表示自己在安全区域状态的线程。在线程离开安全区域时，检查系统是否完成根结点枚举，完成后线程继续执行，否则必须等到收到可以安全离开安全区域的信号为止。 垃圾收集器 两个收集器之间存在连线说明可以搭配使用，所在区域表示它属于新生代收集器还是老年代收集器。 （红色部分为新生代） 1.Serial收集器 单线程收集器，使用一个CPU一条收集线程完成垃圾收集工作，在垃圾收集时必须停掉其他的所有工作线程，直到收集结束。Stop The World 在垃圾收集器不断改进中，停顿时间不短缩小，但是还是没有办法消除。 Serial收集器是虚拟机Client模式下默认的新生代收集器，简单高效，在限定单CPU的情况下，没有线程交互开销。在用户桌面应用场景下，分配给虚拟机管理的内存不大，停顿时间完全在可控范围内。 2.ParNew收集器 Serial的多线程版本，运行在Server模式下虚拟机新生代首选的新生代收集器。 并发：多个线程同时执行（但是在微观上是交替进行的） 并行：多个线程同一时刻都在运行 3.Parallel Scavenge收集器 新生代收集器，使用复制算法，并行的多线程收集器。 特别之处： Parallel Scavenge收集器关注目的是达到一个可以控制的吞吐量。 ​ 吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间） 高吞吐量可以高效利用CPU时间，尽快完成程序的运算任务。 相比之下： CMS等收集器关注尽可能地缩短垃圾收集用户线程停顿时间 停顿时间越短越适合需要与用户交互的程序，良好的相应速度提升用户体验。 Parallel Scavenge收集器两个参数用于精确控制吞吐量。 -XX:MaxGCPauseMillis控制最大的停顿时间 -XX:GCTimeRatio直接设置吞吐量大小 自适应调节策略 Parallel Scavenge收集器被称为吞吐量优先的收集器 -XX:UseAdaptiveSizePolicy参数是一个开关参数，该参数打开，不需要手动指定新生代的大小，Eden与Survivor区的比例，晋升老年代对象的大小等细节参数了，虚拟机会根据当前系统运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间和最大的吞吐量。这种调节方式叫做GC自适应的调节策略。 自适应调节是Parallel Scavenge收集器与ParNew收集器的一个重要区别。 4.Serial Old收集器 使用标记整理算法，单线程老年代收集器，Client模式下虚拟机使用。如果在Server模式下两个用途： 在JDK1.5之前的版本中与Parallel Scavenge收集器搭配使用 作为CMS收集器的后备预案，在并发收集中发生Concurrent Mode Failure时使用 5.Parallel Old收集器 Parallel Old收集器是Parallel Scavenge收集器的老年版本，多线程，标记整理算法。 由于Parallel Scavenge收集器在Parallel Old收集器出现之前，Parallel Scavenge收集器只能与Serial Old配合，Serial在服务器端应用性能拖累，Parallel Scavenge收集器的最大吞吐量不能获得最大化效果。 6.CMS收集器 以获取最短回收停顿时间为目标的收集器，目前大部分Java应用集中在互联网网站或者B/S系统的服务器端上，这类应用重视服务器响应速度，希望停顿时间最短，带来较好的用户体验。 标记清除算法 运行步骤： 初始标记 并发标记 重新标记 并发清除 解释： 其中初始标记和重新标记需要Stop The World。 初始标记标记一下GC Roots能直接关联到的对象，速度快 并发标记阶段进行GC Roots Tracing 的过程 重新标记为了修正并发标记期间因用户程序继续运行而导致的标记产生变化的那一部分对象的标记，这阶段的停顿时间大于初始标记停顿时间。 并发标记和并发清除都可以和用户线程一起运行，从整体上可以看做CMS收集器的内存回收过程与用户线程一起并发执行。 缺点： CPU资源敏感 无法处理浮动垃圾：在CMS进行并发垃圾清除阶段，用户线程还在执行过程中产生的垃圾没有标记，此次GC无法处理这个阶段产生的垃圾，这些垃圾叫做浮动垃圾，只能遗留至下一次GC过程进行垃圾回收。 参数-XX:CMSInitiatingOccupancyFraction设置老年代使用空间达到多少时激活CMS收集器，一般设置为68%，设置阈值偏高会导致，Concurrent Mode Failure，虚拟机启用Serial Old收集器，提高停顿时间性能降低。 由于吃用标记清除算法导致产生大量的内存垃圾 7.G1收集器 内存分配策略 对象优先在Eden分配 大多数情况下，对象会在新生代Eden区中分配，当Eden没有足够的空间，虚拟机发起一次Minor GC。 ​ Minor GC是新生代GC发生在新生代垃圾回收动作，新生代对象朝生夕死，所以Minor GC 频率高，速度快 ​ Major GC/Full GC发生在老年代的垃圾收集动作，速度比Minor GC 慢十倍以上。 大对象直接进入老年代 长期存活的对象直接进入老年代 虚拟机给对象定义年龄计时器，没熬过一次Minor GC，年龄计时器就加1，年龄增长到一定程度就直接晋升老年代。 动态对象年龄判断 在Survivor空间中相同年龄所有对象大小总和大于Survivor空间的一半，年龄大于等于代年龄的对象直接进入老年代。无须达到进入老年代的年龄。 空间分配担保 在发生Minor GC 之前虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象的总空间，这个条件成立，Minor GC可以确保是安全的。如果不成立，虚拟机查看HandlePromotionFailure设置的值是否允许担保失败，如果允许，那么虚拟机继续检查老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小，如果大于就尝试进行Minor GC，这次Minor GC 是有风险的。如果小于，或者HandlePromotionFailure设置不允许冒险，这时就要进行一次Full GC。 为何HotSpot虚拟机要实现两个不同的即时编译器？ 第二部分 虚拟机执行子系统 类文件结构 class文件的头四个字节为魔数，确定这个文件是否为一个被虚拟机接收的class文件，魔数用做身份识别。 接下来的四个字节为class版本号：第五第六个字节为次版本号，第七第八字节为主版本号。高版本JDK可以兼容低版本，但是低版本不能运行高版本class文件。 紧接着为常量池入口，class文件资源仓库，最大数据项目之一，常量池数量不固定需要一个u2类型的数据代表常量池计数值。计数值从1开始。 ​ 常量池两大类常量：字面量和符号引用 ​ 符号引用包括：类和接口的全限定名、字段的名称和描述、方法的名称和描述 访问标志：public final super interface abstract synthetic annotation enum 类索引 父类索引 接口索引集合 字段表集合描述接口或者类中声明的变量 方法表集合 属性表集合 虚拟机类加载机制 类的生命周期：加载、连接（验证、准备、解析）、初始化、使用、卸载。 详细见java高并发详解 第三部分 程序编译代码优化 Javac编译器 HotSpot虚拟机使用c++语言实现，Javac编译器由Java语言编写。 编译的过程： 解析与填充符号表过程：词法分析和语法分析，填充符号表 插入式注解器的注解过程 语义分析字节码生成过程 HotSpot的即时编译器 HotSpot虚拟机是解释器和编译器并存架构，当程序需要迅速启动和执行使用解释器，程序运行后随之时间推移编译器之间发挥作用。 HotSpot虚拟机内部有两个即时编译器Client Compiler和Server Compiler，简化为c1、c2编译器。 主流的HotSpot虚拟机默认采用解释器和其中一个编译器配合使用的工作方式，程序使用哪种编译器主要取决于虚拟机的运行模式。HotSpot虚拟机会根据自身的版本于宿主机器的硬件性能自动选择运行的模式，用户也可通过使用-client或者-server参数强制指定虚拟机运行在哪个模块下。 什么是热点代码？ 被多次调用的方法 被多次调用的循环体 这两种情况，编译器是以对象为编译对象。栈上替换，即方法栈帧还在栈上，方法就被替换。 方法计数器：统计方法调用的次数 回边计数器：统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为回边。 代码优化技术 语言无关的公共子表达式消除 一个表达式已经计算过，并且没有发生变化，那该表达式就是公共子表达式。对于这个表达式直接使用之前的计算结果代替该表达式即可。 如果这种优化仅限于程序基本块内就成为局部公共子表达式消除，如果优化范围覆盖多个基本块就称为全局公共子表达式消除。 语言相关的数组边界检查消除 把运行期检查提到编译期完成。 其他类似优化技术：自动装箱消除，安全点消除、消除反射等等。 方法内联 逃逸分析 逃逸分析的基本行为：分析对象的动态作用域，一个对象被定义后，可能被外部方法引用，例如通过调用参数传递到其他的方法就是方法逃逸。有可能被外部线程访问，例如赋值给类变量或者可以在其他线程中访问该实例对象，叫做线程逃逸。 别的方法或者线程无法通过任何渠道访问这个对象实例，也就是对象不会逃逸到方法或者线程之外。对这个变量进行优化： 栈上分配 Java堆中的对象对于各个线程都是共享和可见的，只要持有该对象的引用就可以访问该对象的数据。如果想要避免这个对象不会逃逸出方法之外，就将其在栈上分配内存，对象所占空间会随着方法调用返回出栈而销毁。一般应用中不会逃逸的局部对象所占的比例较大，如果栈上分配，垃圾回收系统的压力会减小。 同步消除 对这个变量实施同步措施就可以消除其逃逸到别的线程 标量替换 标量是指一个数据已经无法再分解成更小的数据来表示了，Java中的原始数据类型（int，long等数据类型，reference类型）都是不能进一步分解的。如果一个数据可以被分解称为聚合量。 把一个Java对象拆散，根据程序访问情况将其使用到的成员变量恢复原始数据类型来访问叫做标量替换。 如果逃逸分析证明一个对象不会被外部访问，并且这个对象可以被拆散，程序真正执行的时候可能不创建这个对象改为直接创建它的若干个被这个方法使用的成员变量来替换。对象拆分后不仅可以在栈上分配和读写之外，还可以为后续优化创造条件。 Java编译器和C++编译器的对比 代表即时编译器与静态编译器的对比 即时编译器编译过程占用用户线程的运行时间，具有时间压力，如果编译的速度不能达到要求用户程序将会察觉到重大的延迟。严重受制于编译成本，而静态编译器不考虑编译成本。 Java语言是动态类型的编译语言，虚拟机必须频繁的动态检查，对于程序没有明确的检查行为，尽管努力优化但是也会消耗运行时间 Java中没有virtual关键字，但虚方法使用频率远远大于C++语言，所以运行时对方法接收者进行动态选择频率较高。 Java是动态可扩展语言，运行时加载新的类可能改变程序类型的继承关系，使得全局优化难以进行，因为编译器无法看到程序全貌。许多的优化措施只能以激进优化的方式进行。 Java对象大多分配在堆内存，很少分配在栈上。垃圾回收上，C使用代码进行回收，Java中存在无用对象筛选，所以Java在垃圾回收上效率较C低。 Java语言在性能上的劣势为了换取开发上的效率，比如动态安全，动态扩展，垃圾回收机制。","categories":[{"name":"Java","slug":"Java","permalink":"https://duanjiaojiao316.github.io/categories/Java/"}],"tags":[]},{"title":"Java 基础","slug":"Java基础","date":"2019-12-15T12:25:17.000Z","updated":"2021-04-20T07:44:33.811Z","comments":true,"path":"2019/12/15/Java基础/","link":"","permalink":"https://duanjiaojiao316.github.io/2019/12/15/Java%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Java 基础 1、Java特性 继承 super关键字的使用 super关键字的两种用法： 调用超类的构造函数 访问超类中被子类的某个成员隐藏的成员（同名隐藏） 注意： 调用超类构造函数super()必须是子类构造函数中的第一条语句。 必须在构造器的第一行放置super或者this构造器，否则编译器会自动地放一个空参数的super构造器的，其他的构造器也可以调用super或者this，调用成一个递归构造链，最后的结果是父类的构造器（可能有多级父类构造器）始终在子类的构造器之前执行，递归的调用父类构造器。无法执行当前的类的构造器。也就不能实例化任何对象，这个类就成为一个无为类。 从另外一面说，子类是从父类继承而来，继承了父类的属性和方法，如果在子类中先不完成父类的成员的初始化，则子类无法使用，因为在java中不允许调用没初始化的成员。在构造器中是顺序执行的，也就是说必须在第一行进行父类的初始化。而super能直接完成这个功能。this()通过调用本类中的其他构造器也能完成这个功能。 因此，this()或者super()必须放在第一行。 向上转型 1Person s = new Student(15,&quot;djj&quot;,96); 但是用过s引用不能查找子类中的变量实现等。 如果子类覆写父类的一个方法，s调用这个方法，实现是student的实现。 1234567891011121314151617181920212223242526272829303132333435public class Person &#123; protected int age; protected String name; public Person(int age, String name) &#123; this.age = age; this.name = name; &#125; public void print()&#123; System.out.println(&quot;the Person&quot;); &#125;&#125;class Student extends Person&#123; protected int score; public Student(int age, String name, int score) &#123; super(age, name); this.score = score; &#125; public void print()&#123; System.out.println(&quot;the Student&quot;); &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Person s = new Student(15,&quot;djj&quot;,96); s.print(); &#125;&#125;执行结果： the Student 向下转型 向下转型可能会失败，抛出 ClassCastException异常。 区分继承和组合 is关系采用继承，但是has关系使用组合 1234class Student extends Person&#123; protected Book book; protected int score;&#125; 多态 多态是指，针对某个类型的方法调用，其真正执行的方法取决于运行时期实际类型的方法。 利用多态，totalTax()方法只需要和Income打交道，它完全不需要知道Salary和StateCouncilSpecialAllowance的存在，就可以正确计算出总的税。如果我们要新增一种稿费收入，只需要从Income派生，然后正确覆写getTax()方法就可以。把新的类型传入totalTax()，不需要修改任何代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class Income &#123; protected double income; //计算税 public double getTax() &#123; return income * 0.1; &#125;&#125;//工资class Salary extends Income &#123; @Override public double getTax() &#123; if (income &lt;= 5000) &#123; return 0; &#125; return (income - 5000) * 0.2; &#125;&#125;//国家津贴class StateCouncilSpecialAllowance extends Income &#123; @Override public double getTax() &#123; return 0; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Income income = new Income(); income.income = 1000; Salary salary = new Salary(); salary.income = 6000; StateCouncilSpecialAllowance state = new StateCouncilSpecialAllowance(); state.income = 5000; System.out.println(totalTax(salary, state)); System.out.println(totalTax(state)); System.out.println(totalTax(salary)); System.out.println(totalTax(income, salary)); &#125; public static double totalTax(Income... incomes) &#123; double total = 0; for (Income income: incomes) &#123; total = total + income.getTax(); &#125; return total; &#125;&#125;class A&#123; void foo()&#123;&#125;&#125;class B：public A&#123; void foo()&#123;&#125;&#125;A *pa = new B();pa-&gt;foo();执行结果：200.00.0200.0300.0 2、包 2.1包和成员访问 private 无访问修饰符 protected public 在同一个类中是否可见 是 是 是 是 相同的包中的子类 否 是 是 是 相同的包中的非子类 否 是 是 是 不同包中的子类 否 否 是 是 不同包中的非子类 否 否 否 是 public 可以在任何位置访问 默认访问级别 子类或者相同包的下的其他类可以访问 protected 可以在包外访问，但是仅限子类可以访问 private只能在自己的类中访问 3、接口 3.1接口中的变量 可以使用接口将共享的变量导入到多个类中。 123456interface SharedConstants&#123; int NO = 0; int Yes = 1; ...&#125; 这些变量在作用域内会被作为常量。 3.2默认接口方法 在JDK1.8之前没有默认接口方法，默认方法之前使用关键字default。 动机： 给接口添加新的方法，不会破坏之前实现该接口的代码。由于必须实现接口中的所有方法，如果接口加入新的方法，那么实现它的类就必须实现该方法，这样就会破坏现有的代码。 让新方法的实现具有可选性。有些类可以选择不使用。 3.3多级继承问题 一个类实现两个接口，这两个接口提供了相同的方法，这个方法会产生冲突。 类的实现的优先级高于接口默认方法的优先级。所以可以通过类的实现解决冲突。 3.4接口的静态方法 同类的静态方法，无须实现接口，也无须接口的实例，只需要接口名就可以使用接口的默认静态方法。 3.5私有的接口方法 4、异常 4.1链式异常 链式异常可以为异常关联另一个异常，为了描述造成以第一个异常的原因。 构造函数关联 12345678910public Throwable(String message, Throwable cause) &#123; fillInStackTrace(); detailMessage = message; this.cause = cause; &#125; public Throwable(Throwable cause) &#123; fillInStackTrace(); detailMessage = (cause==null ? null : cause.toString()); this.cause = cause; &#125; 支持链式异常的方法 123456789101112public synchronized Throwable getCause() &#123; return (cause==this ? null : cause);&#125;public synchronized Throwable initCause(Throwable cause) &#123; if (this.cause != this) throw new IllegalStateException(&quot;Can&#x27;t overwrite cause with &quot; + Objects.toString(cause, &quot;a null&quot;), this); if (cause == this) throw new IllegalArgumentException(&quot;Self-causation not permitted&quot;, this); this.cause = cause; return this;&#125; getCause方法返回引起当前异常的异常，没有就返回null。 对于每个异常对象只能进行一次initCause，如果使用构造函数关联就不能再使用initCause进行设置。通常initCause方法是为了解决之前不支持链式异常的异常类（不包含支持链式异常的构造方法）不能关联异常设置的。 5、IO (BIO) NIO AIO 5.1 BIO、NIO、AIO的区别 BIO 就是传统的 java.io 包，它是基于流模型实现的，交互的方式是同步、阻塞方式，也就是说在读入输入流或者输出流时，在读写动作完成之前，线程会一直阻塞在那里，它们之间的调用时可靠的线性顺序。它的有点就是代码比较简单、直观；缺点就是 IO 的效率和扩展性很低，容易成为应用性能瓶颈。 NIO 是 Java 1.4 引入的 java.nio 包，提供了 Channel、Selector、Buffer 等新的抽象，可以构建多路复用的、同步非阻塞 IO 程序，同时提供了更接近操作系统底层高性能的数据操作方式。 AIO 是 Java 1.7 之后引入的包，是 NIO 的升级版本，提供了异步非堵塞的 IO 操作方式，所以人们叫它 AIO（Asynchronous IO），异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。 5.2 IO 传统的 IO 大致可以分为4种类型： InputStream、OutputStream 基于字节操作的 IO Writer、Reader 基于字符操作的 IO File 基于磁盘操作的 IO Socket 基于网络操作的 IO InputStream OutputStream Writer Reader 12345678910InputStream inputStream = new FileInputStream(&quot;D:\\\\log.txt&quot;);byte[] bytes = new byte[inputStream.available()];inputStream.read(bytes);String str = new String(bytes, &quot;utf-8&quot;);System.out.println(str);inputStream.close();OutputStream outputStream = new FileOutputStream(&quot;D:\\\\log.txt&quot;,true); // 参数二，表示是否追加，true=追加outputStream.write(&quot;你好，老王&quot;.getBytes(&quot;utf-8&quot;));outputStream.close(); 1234567891011121314Writer writer = new FileWriter(&quot;D:\\\\log.txt&quot;,true); // 参数二，是否追加文件，true=追加writer.append(&quot;老王，你好&quot;);writer.close();Reader reader = new FileReader(&quot;D:\\\\log.txt&quot;);BufferedReader bufferedReader = new BufferedReader(reader);StringBuffer bf = new StringBuffer();String str;while ((str = bufferedReader.readLine()) != null) &#123; bf.append(str + &quot;\\n&quot;);&#125;bufferedReader.close();reader.close();System.out.println(bf.toString()); Java 7 引入了Files（java.nio包下）的，大大简化了文件的读写，如下： 123456789// 写入文件（追加方式：StandardOpenOption.APPEND）Files.write(Paths.get(filePath), Content.getBytes(StandardCharsets.UTF_8), StandardOpenOption.APPEND);// 读取文件byte[] data = Files.readAllBytes(Paths.get(filePath));System.out.println(new String(data, StandardCharsets.UTF_8));// 创建多（单）层目录（如果不存在创建，存在不会报错）new File(&quot;D://a//b&quot;).mkdirs(); 一个简单的 Socket，服务器端只发给客户端信息，再由客户端打印出来的例子，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839int port = 4343; //端口号// Socket 服务器端（简单的发送信息）Thread sThread = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; ServerSocket serverSocket = new ServerSocket(port); while (true) &#123; // 等待连接 Socket socket = serverSocket.accept(); Thread sHandlerThread = new Thread(new Runnable() &#123; @Override public void run() &#123; try (PrintWriter printWriter = new PrintWriter(socket.getOutputStream())) &#123; printWriter.println(&quot;hello world！&quot;); printWriter.flush(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); sHandlerThread.start(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;);sThread.start();// Socket 客户端（接收信息并打印）try (Socket cSocket = new Socket(InetAddress.getLocalHost(), port)) &#123; BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(cSocket.getInputStream())); bufferedReader.lines().forEach(s -&gt; System.out.println(&quot;客户端：&quot; + s));&#125; catch (UnknownHostException e) &#123; e.printStackTrace();&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 调用 accept 方法，阻塞等待客户端连接； 利用 Socket 模拟了一个简单的客户端，只进行连接、读取和打印； 在 Java 中，线程的实现是比较重量级的，所以线程的启动或者销毁是很消耗服务器的资源的，即使使用线程池来实现，使用上述传统的 Socket 方式，当连接数极具上升也会带来性能瓶颈，原因是线程的上线文切换开销会在高并发的时候体现的很明显，并且以上操作方式还是同步阻塞式的编程，性能问题在高并发的时候就会体现的尤为明显。 Writer、Reader 基于字符操作的 IO File 基于磁盘操作的 IO Socket 基于网络操作的 IO 6、 Hashmap是怎么实现的，底层原理？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; /** * The default initial capacity - MUST be a power of two. */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 /** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * The load factor used when none specified in constructor. */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. */ static final int TREEIFY_THRESHOLD = 8; /** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. */ // 当resize操作时候发现链表长度小于6时，从红黑树退化为链表 static final int UNTREEIFY_THRESHOLD = 6; /** * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. */ static final int MIN_TREEIFY_CAPACITY = 64; /** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */ /** * 用于存储map中key和value的结构体 */ transient Node&lt;K,V&gt;[] table; /** * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). */ transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; /** * The number of key-value mappings contained in this map. */ transient int size; /** * The number of times this HashMap has been structurally modified * Structural modifications are those that change the number of mappings in * the HashMap or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the HashMap fail-fast. (See ConcurrentModificationException). */ transient int modCount; /** * The next size value at which to resize (capacity * load factor). * * @serial */ // (The javadoc description is true upon serialization. // Additionally, if the table array has not been allocated, this // field holds the initial array capacity, or zero signifying // DEFAULT_INITIAL_CAPACITY.) int threshold; /** * The load factor for the hash table. * * @serial */ final float loadFactor; transient Node&lt;K,V&gt;[] table;这表示HashMap是Node数组构成，其中Node类的实现如下，为HashMap的内部类，可以看出这其实就是个链表，链表的每个结点是一个&lt;K,V&gt;映射。 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; transient int modCount;``modCount在HashMap，ArrayList和LinkedList中都有，不同之处ArrayList和LinkedList中的modCount继承自AbstractList的protected transient int modCount = 0； 在一个迭代器初始的时候会赋予它调用这个迭代器的对象的modCount，如果在迭代器遍历的过程中，一旦发现这个对象的modCount和迭代器中存储的modCount不一样那就抛异常。 Fail-Fast机制：java.util.HashMap不是线程安全的，因此如果在使用迭代器的过程中有其他线程修改了map，那么将抛出ConcurrentModificationException，这就是所谓fail-fast策略。这一策略在源码中的实现是通过modCount域，modCount顾名思义就是修改次数，**对HashMap内容的修改都将增加这个值，那么在迭代器初始化过程中会将这个值赋给迭代器的expectedModCount。**在迭代过程中，判断modCount跟expectedModCount是否相等，如果不相等就表示已经有其他线程修改了Map。 注意初始容量和扩容后的容量都必须是2的次幂，为什么呢? hash方法 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; HashMap的散列方法如上，其实就是将hash值的高16位和低16位异或，我们将马上看到hash在与n - 1相与的时候，高位的信息也被考虑了，能使碰撞的概率减小，散列得更均匀。 在JDK 8中，HashMap的putVal方法中有这么一句 12if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); 关键就是这句(n - 1) &amp; hash，这行代码是把待插入的结点散列到数组中某个下标中。 为什么HashMap的容量要始终保持2的次幂？ 使散列值分布均匀 位运算的效率比取余的效率高 注意table.length是数组的容量，而transient int size表示存入Map中的键值对数。 int threshold表示临界值，当键值对的个数大于临界值，就会扩容。threshold的更新是由下面的方法完成的。 12345678910static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 该方法返回大于等于cap的最小的二次幂数值。比如cap为16，就返回16，cap为17就返回32。 put方法 put方法主要由putVal方法实现： 如果没有产生hash冲突，直接在数组tab[i = (n - 1) &amp; hash]处新建一个结点； 否则，发生了hash冲突，此时key如果和头结点的key相同，找到要更新的结点，直接跳到最后去更新值 否则，如果数组下标中的类型是TreeNode，就插入到红黑树中 如果只是普通的链表，就在链表中查找，找到key相同的结点就跳出，到最后去更新值；到链表尾也没有找到就在尾部插入一个新结点。接着判断此时链表长度若大于8的话，还需要将链表转为红黑树（注意在要将链表转为红黑树之前，再进行一次判断，若数组容量小于64，则用resize扩容，放弃转为红黑树） get方法 get方法由getNode方法实现： 如果在数组下标的链表头就找到key相同的，那么返回链表头的值 否则如果数组下标处的类型是TreeNode，就在红黑树中查找 否则就是在普通链表中查找了 都找不到就返回null remove方法的流程大致和get方法类似。 HashMap的扩容，resize()过程？ newCap = oldCap &lt;&lt; 1; resize方法中有这么一句，说明是扩容后数组大小是原数组的两倍。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; // 如果数组中只有一个元素，即只有一个头结点，重新哈希到新数组的某个下标 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 数组下标处的链表长度大于1，非红黑树的情况 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // oldCap是2的次幂，最高位是1，其余为是0，哈希值和其相与，根据哈希值的最高位是1还是0，链表被拆分成两条，哈希值最高位是0分到loHead。 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 哈希值最高位是1分到hiHead else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; // loHead挂到新数组[原下标]处； newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; // hiHead挂到新数组中[原下标+oldCap]处 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; 举个例子，比如oldCap是16，二进制表示是10000，hash值的后五位和oldCap相与，因为oldCap的最高位（从右往左数的第5位）是1其余位是0，因此hash值的该位是0的所有元素被分到一条链表，挂到新数组中原下标处，hash值该位为1的被分到另外一条链表，挂到新数组中原下标+oldCap处。举个例子：桶0中的元素其hash值后五位是0XXXX的就被分到桶0种，其hash值后五位是1XXXX就被分到桶4中。 HashTable通过synchronized实现线程安全 1234567891011public synchronized boolean containsKey(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; return true; &#125; &#125; return false; &#125; ConcurrentHashMap ConcurrentHashMap采用了非常精妙的&quot;分段锁&quot;策略，ConcurrentHashMap的主干是个Segment数组。 1final Segment&lt;K,V&gt;[] segments; Segment继承了ReentrantLock，所以它就是一种可重入锁。在ConcurrentHashMap，一个Segment就是一个子哈希表，Segment里维护了一个HashEntry数组，并发环境下，对于不同Segment的数据进行操作是不用考虑锁竞争的。（就按默认的ConcurrentLevel为16来讲，理论上就允许16个线程并发执行） 所以，对于同一个Segment的操作才需考虑线程同步，不同的Segment则无需考虑。 7、transient关键词使用 Java语言的关键字，变量修饰符，如果用transient声明一个实例变量，当对象存储时，它的值不需要维持。换句话来说就是，用transient关键字标记的成员变量不参与序列化过程。 Java的serialization提供了一种持久化对象实例的机制。当持久化对象时，有一个特殊的对象数据成员，不想用serialization机制来保存它。为了在一个特定对象的一个域上关闭serialization，可以在这个域前加上关键字transient。当一个对象被序列化的时候，transient型变量的值不包括在序列化的表示中，然而非transient型的变量是被包括进去的。 8、Java中的错误和异常？ Java中的所有异常都是Throwable的子类对象，Error类和Exception类是Throwable类的两个直接子类。 Error：包括一些严重的、程序不能处理的系统错误类。这些错误一般不是程序造成的，比如StackOverflowError和OutOfMemoryError。 Exception：异常分为运行时异常和检查型异常。 检查型异常要求必须对异常进行处理，要么往上抛，要么try-catch捕获，不然不能通过编译。这类异常比较常见的是IOException。 运行时异常，可处理可不处理，在编译时可以通过，异常在运行时才暴露。比如数组下标越界，除0异常等。 9、Java的集合类框架介绍一下？ 首先接口Collection和Map是平级的，Map没有实现Collection。 Map的实现类常见有HashMap、TreeMap、LinkedHashMap和HashTable等。其中HashMap使用散列法实现，低层是数组，采用链地址法解决哈希冲突，每个数组的下标都是一条链表，当长度超过8时，转换成红黑树。TreeMap使用红黑树实现，可以按照键进行排序。LinkedHashMap的实现综合了HashMap和双向链表，可保证以插入时的顺序（或访问顺序，LRU的实现）进行迭代。HashTable和HashMap比，前者是线程安全的，后者不是线程安全的。HashTable的键或者值不允许null，HashMap允许。 Collection的实现类常见的有List、Set和Queue。List的实现类有ArrayList和LinkedList以及Vector等，ArrayList就是一个可扩容的对象数组，LinkedList是一个双向链表。Vector是线程安全的（ArrayList不是线程安全的）。Set里的元素不可重复，实现类常见的有HashSet、TreeSet、LinkedHashSet等，HashSet的实现基于HashMap，实际上就是HashMap中的Key，同样TreeSet低层由TreeMap实现，LinkedHashSet低层由LinkedHashMap实现。Queue的实现类有LinkedList，可以用作栈、队列和双向队列，另外还有PriorityQueue是基于堆的优先队列。 10、Java反射是什么？为什么要用反射，有什么好处，哪些地方用到了反射？ 反射：允许任意一个类在运行时获取自身的类信息，并且可以操作这个类的方法和属性。这种动态获取类信息和动态调用对象方法的功能称为Java的反射机制。 反射的核心是JVM在运行时才动态加载类或调用方法/访问属性。它不需要事先（写代码的时候或编译期）知道运行对象是谁，如Class.ForName()根本就没有指定某个特定的类，完全由你传入的类全限定名决定，而通过new的方式你是知道运行时对象是哪个类的。 反射避免了将程序“写死”。 反射可以降低程序耦合性，提高程序的灵活性。new是造成紧耦合的一大原因。比如下面的工厂方法中，根据水果类型决定返回哪一个类。 123456789101112131415161718public class FruitFactory &#123; public Fruit getFruit(String type) &#123; Fruit fruit = null; if (&quot;Apple&quot;.equals(type)) &#123; fruit = new Apple(); &#125; else if (&quot;Banana&quot;.equals(type)) &#123; fruit = new Banana(); &#125; else if (&quot;Orange&quot;.equals(type)) &#123; fruit = new Orange(); &#125; return fruit; &#125;&#125;class Fruit &#123;&#125;class Banana extends Fruit &#123;&#125;class Orange extends Fruit &#123;&#125;class Apple extends Fruit &#123;&#125; 但是我们事先并不知道之后会有哪些类，比如新增了Mango，就需要在if-else中新增；如果以后不需要Banana了就需要从if-else中删除。这就是说只要子类变动了，我们必须在工厂类进行修改，然后再编译。如果用反射呢？ 12345678910111213141516public class FruitFactory &#123; public Fruit getFruit(String type) &#123; Fruit fruit = null; try &#123; fruit = (Fruit) Class.forName(type).newInstance(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return fruit; &#125;&#125;class Fruit &#123;&#125;class Banana extends Fruit &#123;&#125;class Orange extends Fruit &#123;&#125;class Apple extends Fruit &#123;&#125; 如果再将子类的全限定名存放在配置文件中。 1class-type=com.fruit.Apple 那么不管新增多少子类，根据不同的场景只需修改文件就好了，上面的代码无需修改代码、重新编译，就能正确运行。 哪些地方用到了反射？举几个例子 加载数据库驱动时 Spring的IOC容器，根据XML配置文件中的类全限定名动态加载类 工厂方法模式中（如上） 反射的使用 获取class实例的方式 直接通过一个class的静态变量class获取： 1Class cls = String.class; 如果我们有一个实例变量，可以通过该实例变量提供的getClass()方法获取： 12String s = &quot;Hello&quot;;Class cls = s.getClass(); 如果知道一个class的完整类名，可以通过静态方法Class.forName()获取： 1Class cls = Class.forName(&quot;java.lang.String&quot;); 因为Class实例在JVM中是唯一的。所以获取的String实例是相同的 123Class a = String.class;Class b = &quot;Hello&quot;.getClass();a == b; //true == 和instanceof的区别 用instanceof不但匹配当前类型，还匹配当前类型的子类。而用==判断class实例可以精确地判断数据类型，但不能作子类型比较。 也就是如果该类是子类instanceof也返回true，但是==返回false 1234567Integer n = new Integer(123);boolean b3 = n instanceof Integer; // trueboolean b4 = n instanceof Number; // trueboolean b1 = n.getClass() == Integer.class; // trueboolean b2 = n.getClass() == Number.class; // false 注意到数组（例如String[]）也是一种Class，而且不同于String.class，它的类名是[Ljava.lang.String。此外，JVM为每一种基本类型如int也创建了Class，通过int.class访问。 获取到了一个Class实例，我们就可以通过该Class实例来创建对应类型的实例。 JVM动态加载 JVM在执行Java程序的时候，并不是一次性把所有用到的class全部加载到内存，而是第一次需要用到class时才加载。 访问字段 通过Class实例获取字段信息。Class类提供了以下几个方法来获取字段： Field getField(name)：根据字段名获取某个public的field（包括父类） Field getDeclaredField(name)：根据字段名获取当前类的某个field（不包括父类） Field[] getFields()：获取所有public的field（包括父类） Field[] getDeclaredFields()：获取当前类的所有field（不包括父类 一个Field对象包含了一个字段的所有信息： getName()：返回字段名称，例如，&quot;name&quot;； getType()：返回字段类型，也是一个Class实例，例如，String.class； getModifiers()：返回字段的修饰符，它是一个int，不同的bit表示不同的含义。 先获取Class实例，再获取Field实例，然后，用Field.get(Object)获取指定实例的指定字段的值。 通过Field.set(Object, Object)实现修改字段的值，其中第一个Object参数是指定的实例，第二个Object参数是待修改的值。 12345678910public static void main(String[] args) throws Exception &#123; Student s = new Student(15,&quot;djj&quot;,96); Student s1 = new Student(16,&quot;why&quot;,97); Class cls = s.getClass(); Field f = cls.getDeclaredField(&quot;score&quot;); System.out.println(f.get(s)); //96 System.out.println(f.get(s1)); //97 f.set(s, 56); System.out.println(s.getScore());//56&#125; 调用方法 通过Class实例获取所有Method信息。Class类提供了以下几个方法来获取Method： Method getMethod(name, Class...)：获取某个public的Method（包括父类） Method getDeclaredMethod(name, Class...)：获取当前类的某个Method（不包括父类） Method[] getMethods()：获取所有public的Method（包括父类） Method[] getDeclaredMethods()：获取当前类的所有Method（不包括父类） 一个Method对象包含一个方法的所有信息： getName()：返回方法名称，例如：&quot;getScore&quot;； getReturnType()：返回方法返回值类型，也是一个Class实例，例如：String.class； getParameterTypes()：返回方法的参数类型，是一个Class数组，例如：&#123;String.class, int.class&#125;； getModifiers()：返回方法的修饰符，它是一个int，不同的bit表示不同的含义。调用非public方法 调用静态方法 12345678910111213141516public class Main &#123; public static void main(String[] args) throws Exception &#123; // 获取Integer.parseInt(String)方法，参数为String: Method m = Integer.class.getMethod(&quot;parseInt&quot;, String.class); // 调用该静态方法并获取结果: Integer n = (Integer) m.invoke(null, &quot;12345&quot;); // 打印调用结果: System.out.println(n); &#125;&#125;int *a;a = new int[45];delete a; 调用非静态方法 123456789101112public class Main &#123; public static void main(String[] args) throws Exception &#123; // String对象: String s = &quot;Hello world&quot;; // 获取String substring(int)方法，参数为int: Method m = String.class.getMethod(&quot;substring&quot;, int.class); // 在s对象上调用该方法并获取结果: String r = (String) m.invoke(s, 6); // 打印调用结果: System.out.println(r); &#125;&#125; 调用非public方法 和Field类似，对于非public方法，我们虽然可以通过Class.getDeclaredMethod()获取该方法实例，但直接对其调用将得到一个IllegalAccessException。为了调用非public方法，我们通过Method.setAccessible(true)允许其调用： 123456789public class Main &#123; public static void main(String[] args) throws Exception &#123; Person p = new Person(); Method m = p.getClass().getDeclaredMethod(&quot;setName&quot;, String.class); m.setAccessible(true); m.invoke(p, &quot;Bob&quot;); System.out.println(p.name); &#125;&#125; 构造实例 1Person p = Person.class.newInstance(); 局限：它只能调用该类的public无参数构造方法。如果构造方法带有参数，或者不是public，就无法直接通过Class.newInstance()来调用。 Java的反射API提供了Constructor对象，它包含一个构造方法的所有信息，可以创建一个实例。Constructor对象和Method非常类似，不同之处仅在于它是一个构造方法，并且，调用结果总是返回实例 通过Class实例获取Constructor的方法如下： getConstructor(Class...)：获取某个public的Constructor； getDeclaredConstructor(Class...)：获取某个Constructor； getConstructors()：获取所有public的Constructor； getDeclaredConstructors()：获取所有Constructor。 Constructor总是当前类定义的构造方法，和父类无关，因此不存在多态的问题。 调用非public的Constructor时，必须首先通过setAccessible(true)设置允许访问。setAccessible(true)可能会失败。 1234567891011121314public class Main &#123; public static void main(String[] args) throws Exception &#123; // 获取构造方法Integer(int): Constructor cons1 = Integer.class.getConstructor(int.class); // 调用构造方法: Integer n1 = (Integer) cons1.newInstance(123); System.out.println(n1); // 获取构造方法Integer(String) Constructor cons2 = Integer.class.getConstructor(String.class); Integer n2 = (Integer) cons2.newInstance(&quot;456&quot;); System.out.println(n2); &#125;&#125; 获取父类，实现接口 通过Class对象可以获取继承关系： Class getSuperclass()：获取父类类型； Class[] getInterfaces()：获取当前类实现的所有接口。 通过Class对象的isAssignableFrom()方法可以判断一个向上转型是否可以实现。 11、说说你对面向对象、封装、继承、多态的理解？ 封装：隐藏实现细节，明确标识出允许外部使用的所有成员函数和数据项。 防止代码或数据被破坏。 继承：子类继承父类，拥有父类的所有功能，并且可以在父类基础上进行扩展。实现了代码重用。子类和父类是兼容的，外部调用者无需关注两者的区别。 多态：一个接口有多个子类或实现类，在运行期间（而非编译期间）才决定所引用的对象的实际类型，再根据其实际的类型调用其对应的方法，也就是“动态绑定”。 Java实现多态有三个必要条件**：继承、重写、向上转型。** 继承：子类继承或者实行父类 重写：在子类里面重写从父类继承下来的方法 向上转型：父类引用指向子类对象 1234567891011121314151617181920212223242526272829303132public class OOP &#123; public static void main(String[] args) &#123; /* * 1. Cat继承了Animal * 2. Cat重写了Animal的eat方法 * 3. 父类Animal的引用指向了子类Cat。 * 在编译期间其静态类型为Animal;在运行期间其实际类型为Cat，因此animal.eat()将选择Cat的eat方法而不是其他子类的eat方法 */ Animal animal = new Cat(); printEating(animal); &#125; public static void printEating(Animal animal) &#123; animal.eat(); &#125;&#125;abstract class Animal &#123; abstract void eat();&#125;class Cat extends Animal &#123; @Override void eat() &#123; System.out.println(&quot;Cat eating...&quot;); &#125;&#125;class Dog extends Animal &#123; @Override void eat() &#123; System.out.println(&quot;Dog eating...&quot;); &#125;&#125; 12、实现不可变对象的策略？比如JDK中的String类。 不提供setter方法（包括修改字段、字段引用到的的对象等方法） 将所有字段设置为final、private 将类修饰为final，不允许子类继承、重写方法。可以将构造函数设为private，通过工厂方法创建。 如果类的字段是对可变对象的引用，不允许修改被引用对象。 1）不提供修改可变对象的方法；2）不共享对可变对象的引用。对于外部传入的可变对象，不保存该引用。如要保存可以保存其复制后的副本；对于内部可变对象，不要返回对象本身，而是返回其复制后的副本。 13、Java序列话中如果有些字段不想进行序列化，怎么办？ 对于不想进行序列化的变量，使用transient关键字修饰。功能是：阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被transient修饰的变量值不会被持久化和恢复。transient只能修饰变量，不能修饰类和方法。 14、==和equals的区别？ == 对于基本类型，比较值是否相等，对于对象，比较的是两个对象的地址是否相同，即是否是指相同一个对象。 equals的默认实现实际上使用了==来比较两个对象是否相等，但是像Integer、String这些类对equals方法进行了重写，比较的是两个对象的内容是否相等。 对于Integer，如果依然坚持使用==来比较，有一些要注意的地方。对于[-128,127]区间里的数，有一个缓存。因此 123456789101112Integer a = 127;Integer b = 127;System.out.println(a == b); // trueInteger a = 128;Integer b = 128;System.out.println(a == b); // false// 不过采用new的方式，a在堆中，这里打印falseInteger a = new Integer(127);Integer b = 127;System.out.println(a == b); 对于String，因为它有一个常量池。所以 12345678String a = &quot;gg&quot; + &quot;rr&quot;;String b = &quot;ggrr&quot;;System.out.println(a == b); // true// 当然牵涉到new的话，该对象就在堆上创建了，所以这里打印falseString a = &quot;gg&quot; + &quot;rr&quot;;String b = new String(&quot;ggrr&quot;);System.out.println(a == b); 15、接口和抽象类的区别？ Java不能多继承，一个类只能继承一个抽象类；但是可以实现多个接口。 继承抽象类是一种IS-A的关系，实现接口是一种LIKE-A的关系。 继承抽象类可以实现对父类代码的复用，也可以重写抽象方法实现子类特有的功能。实现接口可以为类新增额外的功能。 抽象类定义基本的共性内容，接口是定义额外的功能。 调用者使用动机不同, 实现接口是为了使用他规范的某一个行为；继承抽象类是为了使用这个类属性和行为. 16、给你一个Person对象p，如何将该对象变成JSON表示？ 本质是考察Java反射，因为要实现一个通用的程序。实现可能根本不知道该类有哪些字段，所以不能通过get和set等方法来获取键-值。使用反射的getDeclaredFields()可以获得其声明的字段。如果字段是private的，需要调用该字段的f.setAccessible(true);，才能读取和修改该字段。 12345678910111213141516171819202122232425262728import java.lang.reflect.Field;import java.util.HashMap;public class Object2Json &#123; public static class Person &#123; private int age; private String name; public Person(int age, String name) &#123; this.age = age; this.name = name; &#125; &#125; public static void main(String[] args) throws IllegalAccessException &#123; Person p = new Person(18, &quot;Bob&quot;); Class&lt;?&gt; classPerson = p.getClass(); Field[] fields = classPerson.getDeclaredFields(); HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;(); for (Field f: fields) &#123; // 对于private字段要先设置accessible为true f.setAccessible(true); map.put(String.valueOf(f.getName()), String.valueOf(f.get(p))); &#125; System.out.println(map); &#125;&#125; 得到了map，再弄成JSON标准格式就好了。 17、JDBC中sql查询的完整过程？操作事务呢？ 1234567891011121314151617181920212223242526@Testpublic void fun2() throws SQLException, ClassNotFoundException &#123; // 1. 注册驱动 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); String url = &quot;jdbc:mysql://localhost:3306/xxx?useUnicode=true&amp;characterEncoding=utf-8&quot;; // 2.建立连接 Connection connection = DriverManager.getConnection(url, &quot;root&quot;, &quot;admin&quot;); // 3. 执行sql语句使用的Statement或者PreparedStatment Statement statement = connection.createStatement(); String sql = &quot;select * from stu;&quot;; ResultSet resultSet = statement.executeQuery(sql); while (resultSet.next()) &#123; // 第一列是id，所以从第二行开始 String name = resultSet.getString(2); // 可以传入列的索引，1代表第一行，索引不是从0开始 int age = resultSet.getInt(3); String gender = resultSet.getString(4); System.out.println(&quot;学生姓名：&quot; + name + &quot; | 年龄：&quot; + age + &quot; | 性别：&quot; + gender); &#125; // 关闭结果集 resultSet.close(); // 关闭statemenet statement.close(); // 关闭连接 connection.close();&#125; ResultSet维持一个指向当前行记录的cursor（游标）指针 注册驱动 建立连接 准备sql语句 执行sql语句得到结果集 对结果集进行遍历 关闭结果集（ResultSet） 关闭statement 关闭连接（connection） 由于JDBC默认自动提交事务，每执行一个update ,delete或者insert的时候都会自动提交到数据库，无法回滚事务。所以若需要实现事务的回滚，要指定setAutoCommit(false)。 true：sql命令的提交（commit）由驱动程序负责 false：sql命令的提交由应用程序负责，程序必须调用commit或者rollback方法 JDBC操作事务的格式如下，在捕获异常中进行事务的回滚。 12345678try &#123; con.setAutoCommit(false);//开启事务… …. … con.commit();//try的最后提交事务&#125; catch() &#123; con.rollback();//回滚事务&#125; 18、实现单例，有哪些要注意的地方？ 就普通的实现方法来看。 不允许在其他类中直接new出对象，故构造方法私有化 在本类中创建唯一一个static实例对象 定义一个public static方法，返回该实例 1234567891011public class SingletonImp &#123; // 饿汉模式 private static SingletonImp singletonImp = new SingletonImp(); // 私有化（private）该类的构造函数 private SingletonImp() &#123; &#125; public static SingletonImp getInstance() &#123; return singletonImp; &#125;&#125; 饿汉模式：线程安全，不能延迟加载。 1234567891011121314151617public class SingletonImp4 &#123; private static volatile SingletonImp4 singletonImp4; private SingletonImp4() &#123;&#125; public static SingletonImp4 getInstance() &#123; if (singletonImp4 == null) &#123; synchronized (SingletonImp4.class) &#123; if (singletonImp4 == null) &#123; singletonImp4 = new SingletonImp4(); &#125; &#125; &#125; return singletonImp4; &#125;&#125; 双重检测锁+volatile禁止语义重排。因为singletonImp4 = new SingletonImp4();不是原子操作。 123456789101112public class SingletonImp6 &#123; private SingletonImp6() &#123;&#125; // 专门用于创建Singleton的静态类 private static class Nested &#123; private static SingletonImp6 singletonImp6 = new SingletonImp6(); &#125; public static SingletonImp6 getInstance() &#123; return Nested.singletonImp6; &#125;&#125; 静态内部类，可以实现延迟加载。 最推荐的是单一元素枚举实现单例。 写法简单 枚举实例的创建默认就是线程安全的 提供了自由的序列化机制。面对复杂的序列或反射攻击，也能保证是单例 1234public enum Singleton &#123; INSTANCE; public void anyOtherMethod() &#123;&#125;&#125; 19、覆写Object方法 toString()：把instance输出为String； equals()：判断两个instance是否逻辑相等； hashCode()：计算一个instance的哈希值。 在子类的覆写方法中，如果要调用父类的被覆写的方法，可以通过super来调用 。 继承可以允许子类覆写父类的方法。如果一个父类不允许子类对它的某个方法进行覆写，可以把该方法标记为final。用final修饰的方法不能被Override 。final修饰符有多种作用： 20、final关键词 final修饰的方法可以阻止被覆写； final修饰的class可以阻止被继承； final修饰的field必须在创建对象时初始化，随后不可修改。 21、抽象类和接口 default方法 abstract class interface 继承 只能extends一个class 可以implements多个interface 字段 可以定义实例字段 不能定义实例字段 抽象方法 可以定义抽象方法 可以定义抽象方法 非抽象方法 可以定义非抽象方法 可以定义default方法 实现类可以不必覆写default方法。default方法的目的是，当我们需要给接口新增一个方法时，会涉及到修改全部子类。如果新增的是default方法，那么子类就不必全部修改，只需要在需要覆写的地方去覆写新增方法。 default方法和抽象类的普通方法是有所不同的。因为interface没有字段，default方法无法访问字段，而抽象类的普通方法可以访问实例字段。 interface字段 因为interface是一个纯抽象类，所以它不能定义实例字段。但是，interface是可以有静态字段的，并且静态字段必须为final类型： 1234567891011public interface Person &#123; public static final int MALE = 1; public static final int FEMALE = 2;&#125;//因为interface的字段只能是public static final类型，所以我们可以把这些修饰符都去掉，上述代码可以简写为：public interface Person &#123; // 编译器会自动加上public statc final: int MALE = 1; int FEMALE = 2;&#125; 22、作用域 package包作用域 最后，包作用域是指一个类允许访问同一个package的没有public、private修饰的class，以及没有public、protected、private修饰的字段和方法。 public、protected、private略 局部变量 在方法内部定义的变量称为局部变量，局部变量作用域从变量声明处开始到对应的块结束。方法参数也是局部变量。 23、异常和错误 Error和RuntimeException是非受查异常，其他的异常为受查异常。 在程序中无须将非受查异常进行catch或者throws。 在测试阶段可以使用断言来进行。 常见的RuntimeException异常 NullPointerException - 空指针引用异常 ClassCastException - 类型强制转换异常。 IllegalArgumentException - 传递非法参数异常。 ArithmeticException - 算术运算异常 ArrayStoreException - 向数组中存放与声明类型不兼容对象异常 IndexOutOfBoundsException - 下标越界异常 常见的CheckedException异常 SQLException OException ClassNotFoundException NamingException, ServletException, 24、迭代器 迭代器就是提供一种方法对一个容器对象中的各个元素进行访问，而又不暴露该对象容器的内部细节。 Iterator接口的实现如下 迭代器在迭代期间可以从集合中移除元素。 方法名得到了改进，Enumeration的方法名称都比较长。 1234567891011121314151617181920212223package java.util;import java.util.function.Consumer;public interface Iterator&lt;E&gt; &#123; /** * Returns &#123;@code true&#125; if the iteration has more elements. */ boolean hasNext(); /** * Returns the next element in the iteration. */ E next(); default void remove() &#123; throw new UnsupportedOperationException(&quot;remove&quot;); &#125; default void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); while (hasNext()) action.accept(next()); &#125;&#125; Iterable 1234567891011121314151617181920212223package java.lang;import java.util.Iterator;import java.util.Objects;import java.util.Spliterator;import java.util.Spliterators;import java.util.function.Consumer;public interface Iterable&lt;T&gt; &#123; //返回一个Iterator对象 Iterator&lt;T&gt; iterator(); default void forEach(Consumer&lt;? super T&gt; action) &#123; Objects.requireNonNull(action); for (T t : this) &#123; action.accept(t); &#125; &#125; default Spliterator&lt;T&gt; spliterator() &#123; return Spliterators.spliteratorUnknownSize(iterator(), 0); &#125;&#125; 123456789101112131415161718192021###### 两种遍历方式使用迭代器遍历和使用&#96;&#96;&#96;foreach&#96;&#96;&#96;遍历&#96;&#96;&#96;java LinkedList&lt;String&gt; linkedList &#x3D; new LinkedList&lt;&gt;(); linkedList.push(&quot;first&quot;); linkedList.push(&quot;second&quot;); linkedList.push(&quot;third&quot;); linkedList.push(&quot;forth&quot;); linkedList.push(&quot;fifth&quot;); Iterator&lt;String&gt; linkedListIterable &#x3D; linkedList.iterator(); while(linkedListIterable.hasNext())&#123; System.out.println(linkedListIterable.next()); &#125; for (String string:linkedList) &#123; System.out.println(string); &#125; 在使用Iterator的时候禁止对所遍历的容器进行改变其大小结构的操作。例如: 在使用Iterator进行迭代时，如果对集合进行了add、remove操作就会出现ConcurrentModificationException异常。 ListIterator 1234567891011121314151617181920package java.util;public interface ListIterator&lt;E&gt; extends Iterator&lt;E&gt; &#123; boolean hasNext(); E next(); boolean hasPrevious(); E previous(); int nextIndex(); int previousIndex(); void set(E e); void add(E e);&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://duanjiaojiao316.github.io/categories/Java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://duanjiaojiao316.github.io/tags/Java%E5%9F%BA%E7%A1%80/"}]}],"categories":[{"name":"数据库","slug":"数据库","permalink":"https://duanjiaojiao316.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"基础算法","slug":"基础算法","permalink":"https://duanjiaojiao316.github.io/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"name":"后端","slug":"后端","permalink":"https://duanjiaojiao316.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"大数据","slug":"后端/大数据","permalink":"https://duanjiaojiao316.github.io/categories/%E5%90%8E%E7%AB%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"算法","slug":"算法","permalink":"https://duanjiaojiao316.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://duanjiaojiao316.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Java","slug":"Java","permalink":"https://duanjiaojiao316.github.io/categories/Java/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://duanjiaojiao316.github.io/tags/redis/"},{"name":"回文","slug":"回文","permalink":"https://duanjiaojiao316.github.io/tags/%E5%9B%9E%E6%96%87/"},{"name":"Kafka","slug":"Kafka","permalink":"https://duanjiaojiao316.github.io/tags/Kafka/"},{"name":"BFS（广度优先搜索）","slug":"BFS（广度优先搜索）","permalink":"https://duanjiaojiao316.github.io/tags/BFS%EF%BC%88%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%EF%BC%89/"},{"name":"算法 BFS（广度优先搜索）","slug":"算法-BFS（广度优先搜索）","permalink":"https://duanjiaojiao316.github.io/tags/%E7%AE%97%E6%B3%95-BFS%EF%BC%88%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%EF%BC%89/"},{"name":"mysql命令","slug":"mysql命令","permalink":"https://duanjiaojiao316.github.io/tags/mysql%E5%91%BD%E4%BB%A4/"},{"name":"Spring","slug":"Spring","permalink":"https://duanjiaojiao316.github.io/tags/Spring/"},{"name":"阅读笔记","slug":"阅读笔记","permalink":"https://duanjiaojiao316.github.io/tags/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"name":"mybatis","slug":"mybatis","permalink":"https://duanjiaojiao316.github.io/tags/mybatis/"},{"name":"Java基础","slug":"Java基础","permalink":"https://duanjiaojiao316.github.io/tags/Java%E5%9F%BA%E7%A1%80/"}]}